<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bikash-Jaiswal Blog</title>
    <description>You have the capacity to learn from your mistakes, and you will learn a lot today.</description>
    <link>http://bikash-jaiswal.github.io/</link>
    <atom:link href="http://bikash-jaiswal.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 25 Jun 2018 20:45:13 +0530</pubDate>
    <lastBuildDate>Mon, 25 Jun 2018 20:45:13 +0530</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>How they differ? Artificial Intelligence vs machine Learning vs Deep Learning</title>
        <description>&lt;p&gt;We have come far beyond Information Technology age. We are living in &lt;strong&gt;Intelligent&lt;/strong&gt; era. We are surrounded by ubiquitous intelligent device like smart-phones, smart-watch,etc,. Intelligent has become banal not only in regular life style but also affecting the industries too. Devices which have &lt;strong&gt;Artificial Intelligence&lt;/strong&gt; has started changing the world drastically. As Andrew Ng stated &lt;em&gt;“Like electricity changed the world a century ago, similarly AI will change the world like never before”&lt;/em&gt;.  Nowadays we look for intelligent software to automate banal labor, understand speech, or images, make diagnosis in medicine and support basic scientific research.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Artificial intelligence”: When a machine mimics “cognitive” functions that humans associate with other human minds, such as “learning” and “problem solving” - Russell &amp;amp; Norvig, 2009&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We all are familiar with word Artificial Intelligence form movies like “The Terminator”, “The Matrix”, “A Space Odyssey”, etc and best classic novels like “Frankenstein”, “The Hitchhiker guide to the Galaxy”, and many more. But it’s an arduous task to explain Artificial Intelligence to novice and distinguish it for its branches like &lt;strong&gt;Machine Learning&lt;/strong&gt; and &lt;strong&gt;Deep Learning&lt;/strong&gt;, &lt;strong&gt;Reinforcement learning&lt;/strong&gt;. In this post, I will try to explain in a laconic way despite being cogent: How AI, Machine Learning and Deep learning are different from each other nevertheless, shelter under the same umbrella.&lt;/p&gt;

&lt;p&gt;During 1900s, when researcher discovered that digital computers can simulate any process of formal reasoning a.k.a Church–Turing thesis- an idea was embroiled among the researchers. The idea to accumulate understanding from &lt;strong&gt;Neurobiology&lt;/strong&gt;, &lt;strong&gt;Information Theory&lt;/strong&gt;, &lt;strong&gt;Cybernetics&lt;/strong&gt; and many other branches of Natural science and engineering to build a &lt;strong&gt;electronic brain&lt;/strong&gt; or &lt;strong&gt;artificial brain&lt;/strong&gt;. Then, the perennial movement of Artificial Intelligence begun.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/2018-05-30/Artificial-Brain.png&quot; alt=&quot;my alt text&quot; /&gt;
    &lt;figcaption&gt; Artificial brain. &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;An artificial brain (or artificial mind) is software and hardware with cognitive
abilities similar to those of the animal or human brain. -
BBC News,2009&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;classical-ai&quot;&gt;Classical AI&lt;/h2&gt;
&lt;p&gt;Earlier/classical AI system are built on a list of formal, logistic and mathematical rules. Some such rules were Informed/Uninformed search strategies, Propositional Logic, First Order Logic, Planning, Heuristics functions, etc,.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/2018-05-30/knowledge-based-systems.jpg&quot; alt=&quot;kNR&quot; /&gt;
    &lt;figcaption&gt;Contains of Knowledge based Systems. &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt; &lt;/p&gt;

&lt;p&gt;We feted IBM’s Deep chess-playing system when it defeated world champion Garry Kasparov. But the system was completely rules and logic based system. If you know the board position, it is possible to know all you need to know to play the game, because given a certain board position, the possible moves are precisely defined and finite in number. Even though you may not know the particular move your opponent will make, you know that he will make a legal move. A system for defeating games like chess, tic-tac-toe, AlphaGO, etc can be built by programmer ahead of competition from a list of complete formal rules and logics. Thus classic AI is known as &lt;strong&gt;Knowledge based Intelligent System&lt;/strong&gt;.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/2018-05-30/tic-toc-toe.png&quot; alt=&quot;tic-tac-toe&quot; /&gt;
    &lt;figcaption&gt; Game tree of tic-tac-toe. Courtesy: Google DeepMind's AlphaGo: How it works
 &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt; &lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/2018-05-30/tree-based.png&quot; alt=&quot;tree-based&quot; /&gt;
    &lt;figcaption&gt;Tree based search system for GO. Courtesy Google's Deepmind &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt; &lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;problem&lt;/strong&gt; with the classical AI is: it’s inability to learn from environment or to extract and acquire their own knowledge from patterns of raw data provided to them. As they are bolstered by hand-coded knowledge.&lt;/p&gt;

&lt;p&gt;The list of Instance where classical AI fails:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Unable to extract information from real world for ex: camera images, typically in the form of a pixel array, and map them onto internal representations of the world&lt;/li&gt;
  &lt;li&gt;Classical AI models do not take the real world sufficiently into account. so, problem of generalization occurs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;machine-learning&quot;&gt;Machine Learning.&lt;/h2&gt;
&lt;p&gt;Machine Learning solves the problems classical AI by providing systems the ability to acquire their own knowledge by extracting information from real world data.&lt;/p&gt;

&lt;p&gt;Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed. Let me give you formal Book definition:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.” - Tom Mitchell’s Machine Learning Book&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A bit scary definition right? So, let me delineate it simply:
Let us say a machine is playing checker game.
The T, P, and E can be well defined by&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;E = the experience of playing many games of checkers&lt;/li&gt;
  &lt;li&gt;T = the task of playing checkers.&lt;/li&gt;
  &lt;li&gt;P = the probability that the program will win the next game.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With every experience ( E ) collected from environment or dataset or game, what decisions or tasks ( T ) the player has to take, so probability ( P ) of win is maximized.&lt;/p&gt;

&lt;p&gt;The performance of every machine learning algorithms depends on the &lt;strong&gt;representation&lt;/strong&gt; aka &lt;strong&gt;features&lt;/strong&gt; of the data they are given. This features helps AI to retain knowledge of patterns from raw data provided to them. The machine learning algorithm learns from data by correlating each features of data with various output.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/2018-05-30/ml-algorithm.png&quot; alt=&quot;ml-algorithm&quot; /&gt;
    &lt;figcaption&gt;Different types of Machine Learning Algorithm. &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt; &lt;/p&gt;

&lt;p&gt;It is not surprising that the choice of features has an colossal effect on the performance of machine learning algorithms. However, it is difficult to know what feature should be extracted for best performance of machine learning algorithm. For example, if MRI scan of the patient are given to Logistic Regression, it would not be able to make useful prediction as all the features are uniform in the form of pixel.&lt;/p&gt;

&lt;p&gt;Hence, the &lt;strong&gt;problem&lt;/strong&gt; with machine learning- it’s little bleak to use ML algorithm when we have difficult to extract a representation or best features to solve problem.&lt;/p&gt;

&lt;p&gt;The list of instance where machine Learning algorithm fails:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ML algorithms fails to give better result when datasets or representation of datasets is unstructured like images, audio, video.&lt;/li&gt;
  &lt;li&gt;It fails when there is no more data for learning purpose.&lt;/li&gt;
  &lt;li&gt;ML fail when, among the training examples, there are often similar inputs that are associated to different outputs.&lt;/li&gt;
  &lt;li&gt;Ml algorithms are designed to deal with noise in datasets at certain level but as more noise increase more difficult learning process becomes, which leads to bad accuracy.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-learning&quot;&gt;Deep Learning.&lt;/h2&gt;
</description>
        <pubDate>Wed, 30 May 2018 00:00:00 +0530</pubDate>
        <link>http://bikash-jaiswal.github.io/2018/05/30/Introduction-to-Artificial-Intelligence-and-its-branches.html</link>
        <guid isPermaLink="true">http://bikash-jaiswal.github.io/2018/05/30/Introduction-to-Artificial-Intelligence-and-its-branches.html</guid>
        
        <category>Artificial-Intelligence</category>
        
        
        <category>AI</category>
        
      </item>
    
      <item>
        <title>How to Structure Machine Learning Projects</title>
        <description>&lt;p&gt;Even after developing a model, We find that prediction accuracy is 90% but that isn’t good enough for production purpose because there are whole 10% error in prediction. So, we apply some technique to improve it like:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Collecting more diverse positive and negative training data&lt;/li&gt;
  &lt;li&gt;train the algorithm with gradient descent or use advance optimization algorithm like Adam.&lt;/li&gt;
  &lt;li&gt;Trying different network from smaller to bigger&lt;/li&gt;
  &lt;li&gt;also trying different regularization and dropout or changing the activation functions and number of hidden units.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-to-structure-machine-learning-projects&quot;&gt;How to Structure Machine Learning Projects&lt;/h2&gt;
&lt;p&gt;Applying above technique may not give always give desired result despite spending months on collecting data. Therefore, Some strategies is necessary which helps us in improving the accuracy of models.&lt;/p&gt;

&lt;h3 id=&quot;orthogonalization&quot;&gt;Orthogonalization&lt;/h3&gt;
&lt;p&gt;There are hundreds of parameters and hyperparameters to tune to increase the prediction accuracy but it’s cumbersome and tedious task to do. Here comes the role orthogonalization or orthogonality.&lt;/p&gt;

&lt;p&gt;The word orthogonal means “Statistically independent”. So,&lt;code class=&quot;highlighter-rouge&quot;&gt;Orthogonalization or orthogonality can be stated as a system design property that assures that modifying an instruction or a component of an algorithm will not create or propagate side effects  to  other components of the system.&lt;/code&gt; It becomes easier to verify the algorithms independently from one another, it reduces testing and development time.&lt;/p&gt;

&lt;p&gt;Let’s take to metaphorical example of old television and car steering.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/tv-car.jpg&quot; alt=&quot;my alt text&quot; /&gt;
    &lt;figcaption&gt; Metaphor for orthogonality &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;We can tune the picture on tv by varying the properties of knob of tv. Similarly, changing the steering of car can makes change in different direction to go.&lt;/p&gt;

&lt;p&gt;When a supervised learning system is design, these are the 4 assumptions that needs to be true and orthogonal.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Fit training set well in cost function
    &lt;ul&gt;
      &lt;li&gt;If it doesn’t fit well then use of a bigger neural network or use a better optimization algorithm.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Fit development set well on cost function
    &lt;ul&gt;
      &lt;li&gt;If it doesn’t fit well then use regularization or use bigger training set and use bigger training set.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Fit test set well on cost function
    &lt;ul&gt;
      &lt;li&gt;If it doesn’t fit well then use bigger Development set&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Performs well in real world
    &lt;ul&gt;
      &lt;li&gt;If it doesn’t fit well then change development set  or cost function.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;different-tuning-method-or-method-for-improving-our-model&quot;&gt;Different tuning method or method for improving our model.&lt;/h3&gt;
&lt;h4 id=&quot;using-a-single-number-evaluations-metric-ief1-score&quot;&gt;Using a single number evaluations metric. i.e.F1 score&lt;/h4&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/img/ml-strategies/decision.png&quot; alt=&quot;my alt text&quot; /&gt;
    &lt;figcaption&gt; Confusion Matrix &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Precision&lt;/strong&gt; : Of all the images we predicted y=1, what fraction of it have cats?&lt;/p&gt;
&lt;figure&gt;
   &lt;div style=&quot;text-align:center&quot;&gt;
     &lt;img src=&quot;/assets/img/ml-strategies/precision.png&quot; alt=&quot;my alt text&quot; /&gt;
   &lt;/div&gt;
 &lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Recall&lt;/strong&gt; : Of all the images that actually have cats, what fraction of it did we correctly identifying have cats?&lt;/p&gt;
&lt;figure&gt;
   &lt;div style=&quot;text-align:center&quot;&gt;
     &lt;img src=&quot;/assets/img/ml-strategies/recall.png&quot; alt=&quot;my alt text&quot; /&gt;
   &lt;/div&gt;
 &lt;/figure&gt;

&lt;p&gt;Let’s compare 2 classifiers A and B used to evaluate if there are cat images:&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/evaluation-matrix.png&quot; alt=&quot;my alt text&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;In this case the evaluation metrics are precision and recall.&lt;/p&gt;

&lt;p&gt;For classifier A, there is a 95% chance that there is a cat in the image and a 90% chance that it has correctly detected a cat. Whereas for classifier B there is a 98% chance that there is a cat in the image and a 85% chance that it has correctly detected a cat.&lt;/p&gt;

&lt;p&gt;The problem with using precision/recall as the evaluation metric is that you are not sure which one is better since in this case, both of them have a good precision et recall. F1-score, a harmonic mean, combine both precision and recall.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/F1-score.png&quot; alt=&quot;my alt text&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;Classifier A is a better choice. F1-Score is not the only evaluation metric that can be use, the average, for
example, could also be an indicator of which classifier to use.&lt;/p&gt;

&lt;h4 id=&quot;satisficing-and-optimizing-metrics&quot;&gt;Satisficing and optimizing metrics.&lt;/h4&gt;
&lt;p&gt;There are different metrics to evaluate the performance of a classifier, they are called &lt;code class=&quot;highlighter-rouge&quot;&gt;evaluation matrices&lt;/code&gt;.
They can be categorized as &lt;code class=&quot;highlighter-rouge&quot;&gt;satisficing&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;optimizing&lt;/code&gt; matrices. It is important to note that these evaluation matrices must be evaluated on a training set, a development set or on the test set.&lt;/p&gt;

&lt;blockquote&gt;

  &lt;ul&gt;
    &lt;li&gt;optimizing —&amp;gt; best accuracy&lt;/li&gt;
    &lt;li&gt;satisficing —&amp;gt; running &amp;lt;= X ms.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/3table.png&quot; alt=&quot;my alt text&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;In this case, accuracy and running time are the evaluation matrices. Accuracy is the optimizing metric,
because you want the classifier to correctly detect a cat image as accurately as possible. The running time
which is set to be under 100 ms in this example, is the satisficing metric which mean that the metric has
to meet expectation set.&lt;/p&gt;

&lt;h4 id=&quot;traindevtest-set-distributions&quot;&gt;Train/dev/test set distributions&lt;/h4&gt;
&lt;p&gt;Setting up the training, development and test sets have a huge impact on productivity. It is important to
choose the development and test sets from the same distribution and it must be taken randomly from all
the data. &lt;code class=&quot;highlighter-rouge&quot;&gt;Test set should be big enough to give high confidence in the overall performance of your system.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;In dataset where data instances are few like below 100,000, researcher has used 80-20 rule.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/old-dist.png&quot; alt=&quot;my alt text&quot; /&gt;
    &lt;figcaption&gt; Strategy of distribution in machine learning &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;but because of generation Big Data, they have changed the rule to 98-1-1.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/new-dist.png&quot; alt=&quot;my alt text&quot; /&gt;
    &lt;figcaption&gt; Strategy of distribution in Deep Learning &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;h4 id=&quot;when-to-change-devtest-sets-and-metrics&quot;&gt;When to change dev/test sets and metrics&lt;/h4&gt;
&lt;p&gt;A cat classifier tries to find a great amount of cat images to show to cat loving users. The evaluation metric used is a classification error.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/error.png&quot; alt=&quot;my alt text&quot; /&gt;
    &lt;figcaption&gt; Strategy of distribution in machine learning &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;It seems that &lt;code class=&quot;highlighter-rouge&quot;&gt;Algorithm A is better than Algorithm B&lt;/code&gt; since there is only a 3% error, however for some reason, Algorithm A is letting through a lot of the pornographic images. Algorithm B has 5% error thus it classifies fewer images but it doesn’t have pornographic images. From a company’s point of view, as well as from a user acceptance point of view, &lt;code class=&quot;highlighter-rouge&quot;&gt;Algorithm B is actually a better
algorithm&lt;/code&gt;. The evaluation metric fails to correctly rank order preferences between algorithms. The evaluation metric or the development set or test set should be changed.&lt;/p&gt;

&lt;p&gt;The misclassification error metric can be written as a function as follow:&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/misclass.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;This function counts up the number of misclassified examples.
The problem with this evaluation metric is that it treats pornographic vs non-pornographic images equally. On way to change this evaluation metric is to add the weight term 𝑤&lt;sup&gt;(𝑖)&lt;/sup&gt;.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/more-weight.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The function becomes:&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/changed-equation.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Reminder&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define correctly an evaluation metric that helps better rank order classifiers&lt;/li&gt;
  &lt;li&gt;Optimize the evaluation metric&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;summary-of-orthogonalization&quot;&gt;Summary of orthogonalization&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;[x] Define a metric to evaluate a classifier&lt;/li&gt;
  &lt;li&gt;[x] Separately improve the metric to improve accuracy&lt;/li&gt;
  &lt;li&gt;[x] Change metric and/or dev/test set, if previous choosen  metric + dev/test fails.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 20 Apr 2018 00:00:00 +0530</pubDate>
        <link>http://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html</link>
        <guid isPermaLink="true">http://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html</guid>
        
        <category>Deep-Learning</category>
        
        
        <category>Deep</category>
        
        <category>Learning</category>
        
        <category>Notes</category>
        
      </item>
    
      <item>
        <title>Practical aspects of Deep Learning</title>
        <description>&lt;p&gt;After implementation of a neural network, we have gained enough vim to better understand the black box of Deep Learning and to learn all the practical aspects of making our neural network work even better. We are going to learn various tricks or technique like:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Hyperparameter tuning&lt;/li&gt;
  &lt;li&gt;Setting the datasets&lt;/li&gt;
  &lt;li&gt;Optimization algorithm- makes learning algorithm to learn in a reasonable time&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;practical-aspects-of-deep-learning&quot;&gt;Practical aspects of Deep Learning&lt;/h2&gt;
&lt;p&gt;When we start to solve a new problem in using deep learning, we can never decide earlier what to choose like - what learning rate? how many hidden layers? which activation functions to choose and for which layers? To find the answer we have to follow iterative process of &lt;code class=&quot;highlighter-rouge&quot;&gt;Idea ---&amp;gt; code ---&amp;gt; Experiment&lt;/code&gt;. Even seasoned deep learning expert find it almost impossible to correctly guess the best choice of hyperparameters the very first time.&lt;/p&gt;

&lt;h3 id=&quot;setting-up-your-machine-learning-application&quot;&gt;Setting up your Machine Learning Application&lt;/h3&gt;
&lt;h5 id=&quot;train--dev--test-sets&quot;&gt;1. Train / Dev / Test sets&lt;/h5&gt;
&lt;p&gt;Your data will be split into three parts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Training set. (Has to be the largest set)&lt;/li&gt;
  &lt;li&gt;Development or “dev” set.&lt;/li&gt;
  &lt;li&gt;Testing set.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
  &lt;img src=&quot;/assets/img/ml-strategies/new-dist.png&quot; alt=&quot;my alt text&quot; /&gt;
      &lt;figcaption&gt; Strategy of distribution in Deep Learning &lt;/figcaption&gt;
    &lt;/div&gt;
  &lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;Generally, we have give just Training set and Test set in real life and also in Kaggle competitions. To construct the development set use following technique:&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Test set size = 10,000,000, then split like below&lt;/li&gt;
    &lt;li&gt;Test set size = index from 1 - 9,900,000 i.e. 98% of original test set&lt;/li&gt;
    &lt;li&gt;Development set = index from 9,900,001 - 10,000,000 i.e. 1% of original test sets.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;You will try to build a model upon training set then try to optimize hyperparameters on dev set as much as possible. Then after your model is ready you try and evaluate the testing set.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Make sure the dev and test set are coming from the same distribution&lt;/code&gt;. Suppose training pictures is from the web and the dev/test pictures are from users cell phone they will mismatch. It is better to make sure that dev and test set are from the same distribution.&lt;/p&gt;

&lt;p&gt;For more knowledge on Train/dev/test set distributions topic follow &lt;a href=&quot;https://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html&quot;&gt;Machine Learning Strategy In Deep Learning&lt;/a&gt; 3rd course in Deep learning specialization.&lt;/p&gt;

&lt;h5 id=&quot;bias---variance&quot;&gt;2. Bias - Variance&lt;/h5&gt;

&lt;p&gt;One of the quick question to evaluate someone’s technical skill on Machine Learning or Deep Learning is to ask him/her about bias/ Variance and Overfitting and Underfitting.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;It is simple and vital topic but difficult to master.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;More information on the problem of overfitting and underfitting can be found on &lt;a href=&quot;https://github.com/bikash-jaiswal/Machine-Learning-Notes/blob/master/3.a.The-problem-of-overfitting.md&quot;&gt;The problem of Underfitting&lt;/a&gt; course for Machine learning taught by Andrew Ng in &lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot;&gt;coursera&lt;/a&gt;.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/bias-variance.png&quot; alt=&quot;Bias-variance&quot; /&gt;
    &lt;figcaption&gt; Bias-Variance &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Overfitting&lt;/strong&gt; : models with overfitting problem has good performance on the training data, poor generliazation to other data. It is usually caused by a complicated function that creates a lot of unnecessary curves and angles unrelated to the data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Underfitting&lt;/strong&gt;: models that can neither model the training data nor generalize to new data. It is usually caused by a function that is too simple or uses too few features.&lt;/p&gt;

&lt;p&gt;Analysis Bias and Variance with training error rate and validation error value. Assumption made for below comparison: human error = 0%&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;High variance (overfitting):
    &lt;ul&gt;
      &lt;li&gt;Training error: 1%&lt;/li&gt;
      &lt;li&gt;Dev error: 11%&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;High Bias (underfitting):
    &lt;ul&gt;
      &lt;li&gt;Training error: 15%&lt;/li&gt;
      &lt;li&gt;Dev error: 14%&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;High Bias (underfitting) &amp;amp;&amp;amp; High variance (overfitting) :
    &lt;ul&gt;
      &lt;li&gt;Training error: 15%&lt;/li&gt;
      &lt;li&gt;Test error: 30%&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Best:
    &lt;ul&gt;
      &lt;li&gt;Training error: 0.5%&lt;/li&gt;
      &lt;li&gt;Test error: 1%&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To know more about human level performance see &lt;a href=&quot;https://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html&quot;&gt;Machine Learning Strategy In Deep Learning&lt;/a&gt; 3rd course in Deep learning specialization.&lt;/p&gt;

&lt;h5 id=&quot;basic-recipe-for-machine-learning&quot;&gt;3. Basic Recipe for Machine Learning&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;If your algorithm has a high bias:
    &lt;ul&gt;
      &lt;li&gt;Try to make your NN bigger (size of hidden units, number of layers)&lt;/li&gt;
      &lt;li&gt;Try a different model that is suitable for your data.
Try to run it longer.
Different (advanced) optimization algorithms.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If your algorithm has a high variance:
    &lt;ul&gt;
      &lt;li&gt;More data.&lt;/li&gt;
      &lt;li&gt;Try regularization.&lt;/li&gt;
      &lt;li&gt;Try a different model that is suitable for your data.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You should try the previous two points until you have a low bias and low variance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In the older days before deep learning, there was a “Bias/variance trade-off”. But because now you have more options/tools for solving the bias and variance problem its really helpful to use deep learning.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Training a bigger neural network never hurts.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;regularizing-your-neural-network&quot;&gt;Regularizing your neural network&lt;/h3&gt;
&lt;p&gt;As of solution listed in case of high variance, getting more data is not always feasible in every case of application, nevertheless, trying regularization is always possible.&lt;/p&gt;

&lt;h5 id=&quot;applying-regularization-in-logistic-regression&quot;&gt;Applying regularization in logistic regression&lt;/h5&gt;
&lt;p&gt;Here, &lt;code class=&quot;highlighter-rouge&quot;&gt;||W|| = sum of absolute values of all weight&lt;/code&gt; and the cost function of logistic regression is &lt;code class=&quot;highlighter-rouge&quot;&gt;J(w,b) = (1/m) * Sum(L(y(i),y'(i)))&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda&lt;/code&gt; is  regularization parameter (another hyperparameter).&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/regularization-LR.png&quot; alt=&quot;regularization in Logistic regression&quot; /&gt;
    &lt;figcaption&gt; Regularization in Logistic Regression &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;Though &lt;code class=&quot;highlighter-rouge&quot;&gt;L2 regularization is used much&lt;/code&gt; despite &lt;code class=&quot;highlighter-rouge&quot;&gt;L1 regularization&lt;/code&gt;, people thinks, can help with compressing the model as it makes &lt;code class=&quot;highlighter-rouge&quot;&gt;W&lt;/code&gt; sparse by setting some of W’s value zero and also uses less memory to store the model.&lt;/p&gt;

&lt;h5 id=&quot;regularization-in-neural-network&quot;&gt;Regularization in Neural Network.&lt;/h5&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/regu-nn.png&quot; alt=&quot;regularization in Neural network&quot; /&gt;
    &lt;figcaption&gt; Regularization in Neural Network &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Update the gradient of &lt;code class=&quot;highlighter-rouge&quot;&gt;W&lt;/code&gt; by:
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dW[l] = (from backpropagation) +  lambda/m * W[l] &lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;W[l] = W[l] -lr*dW[l]&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;w[l] = w[l] - lr * dw[l]
     = w[l] - lr * ((from back propagation) + lambda/m * w[l])
     = w[l] - (lr*lambda/m) * w[l] - lr * (from back propagation)
     = (1 - (lr*lambda)/m) * w[l] - lr * (from back propagation)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The new term &lt;code class=&quot;highlighter-rouge&quot;&gt;(1 - (learning_rate*lambda)/m) * w[l]&lt;/code&gt; causes the weight to decay in proportion to its size.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(lambda/2m) * Sum((||W[l]||^2)&lt;/code&gt;  penalizes the weight matrices from being too large.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;how-does-regularization-prevent-overfitting&quot;&gt;How does regularization prevent overfitting&lt;/h5&gt;
&lt;p&gt;Some Intuition that can help us in finding why and how does regularization help with overfitting and reducing variance problems?&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Intuition I&lt;/code&gt;: If regularization parameter &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda&lt;/code&gt; is too big.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a lot of w’s will be close to zeros which will make the Neural network simpler (you can think of it as it would behave closer to logistic regression with more hidden layers).&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
    &lt;div style=&quot;text-align:center&quot;&gt;
      &lt;img src=&quot;/assets/img/practical-aspect/simpler-nn.png&quot; alt=&quot;simpler-nn&quot; /&gt;
      &lt;figcaption&gt; NN when lambda is too large &lt;/figcaption&gt;
    &lt;/div&gt;
  &lt;/figure&gt;
&lt;ul&gt;
  &lt;li&gt;If lambda is good enough: It will just reduce some weights that makes the neural network overfit.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Intuition II with tanh function&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If lambda is too large, w’s will be small (close to zero) - will use the linear part of the tanh activation function, so we will go from non linear activation to roughly linear which would make the NN a roughly linear classifier.&lt;/li&gt;
  &lt;li&gt;If lambda good enough it will just make some of tanh activations roughly linear which will prevent overfitting.&lt;/li&gt;
  &lt;li&gt;If lambda is good enough: It will just reduce some weights that makes the neural network overfit.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Implementation tip&lt;/code&gt;&lt;/strong&gt;: If you implement gradient descent, one of the steps to debug gradient descent is to plot the cost function (J) as a function of the number of iterations of gradient descent and you want to see that the cost function J &lt;strong&gt;decreases monotonically&lt;/strong&gt; after every elevation of gradient descent with regularization. If you plot the old definition of J (no regularization) then you might not see it decrease monotonically.
monotonically decreassing&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/monotonically decreassing.png&quot; alt=&quot;monotonically decreassing&quot; /&gt;
    &lt;figcaption&gt;monotonically decreassing
 &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;setting-up-your-optimization-problem&quot;&gt;Setting up your optimization problem&lt;/h3&gt;

&lt;h3 id=&quot;different-optimization-algorithms&quot;&gt;Different Optimization algorithms&lt;/h3&gt;

&lt;h3 id=&quot;hyperparameter-tuning&quot;&gt;Hyperparameter tuning&lt;/h3&gt;

&lt;h3 id=&quot;batch-normalization&quot;&gt;Batch Normalization&lt;/h3&gt;

&lt;h3 id=&quot;multiclass-classification&quot;&gt;Multiclass classification&lt;/h3&gt;
</description>
        <pubDate>Mon, 16 Apr 2018 00:00:00 +0530</pubDate>
        <link>http://bikash-jaiswal.github.io/2018/04/16/Practical-aspects-of-Deep-Learning.html</link>
        <guid isPermaLink="true">http://bikash-jaiswal.github.io/2018/04/16/Practical-aspects-of-Deep-Learning.html</guid>
        
        <category>Deep-Learning</category>
        
        
        <category>Deep</category>
        
        <category>Learning</category>
        
        <category>Notes</category>
        
      </item>
    
  </channel>
</rss>
