<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bikash-Jaiswal Blog</title>
    <description>You have the capacity to learn from your mistakes, and you will learn a lot today.</description>
    <link>http://bikash-jaiswal.github.io/</link>
    <atom:link href="http://bikash-jaiswal.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Fri, 29 Jun 2018 19:24:05 +0530</pubDate>
    <lastBuildDate>Fri, 29 Jun 2018 19:24:05 +0530</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>How they differ? Artificial Intelligence vs machine Learning vs Deep Learning</title>
        <description>&lt;p&gt;We have come far beyond Information Technology age. We are living in &lt;strong&gt;Intelligent&lt;/strong&gt; era. We are surrounded by ubiquitous intelligent device like smart-phones, smart-watch,etc,. Intelligent has become banal not only in regular life style but also affecting the industries too. Devices which have &lt;strong&gt;Artificial Intelligence&lt;/strong&gt; has started changing the world drastically. As Andrew Ng stated &lt;em&gt;‚ÄúLike electricity changed the world a century ago, similarly AI will change the world like never before‚Äù&lt;/em&gt;.  Nowadays we look for intelligent software to automate banal labor, understand speech, or images, make diagnosis in medicine and support basic scientific research.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚ÄúArtificial intelligence‚Äù: When a machine mimics ‚Äúcognitive‚Äù functions that humans associate with other human minds, such as ‚Äúlearning‚Äù and ‚Äúproblem solving‚Äù - Russell &amp;amp; Norvig, 2009&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We all are familiar with word Artificial Intelligence form movies like ‚ÄúThe Terminator‚Äù, ‚ÄúThe Matrix‚Äù, ‚ÄúA Space Odyssey‚Äù, etc and best classic novels like ‚ÄúFrankenstein‚Äù, ‚ÄúThe Hitchhiker guide to the Galaxy‚Äù, and many more. But it‚Äôs an arduous task to explain Artificial Intelligence to novice and distinguish it for its branches like &lt;strong&gt;Machine Learning&lt;/strong&gt; and &lt;strong&gt;Deep Learning&lt;/strong&gt;, &lt;strong&gt;Reinforcement learning&lt;/strong&gt;. In this post, I will try to explain in a laconic way despite being cogent: How AI, Machine Learning and Deep learning are different from each other nevertheless, shelter under the same umbrella.&lt;/p&gt;

&lt;p&gt;During 1900s, when researcher discovered that digital computers can simulate any process of formal reasoning a.k.a Church‚ÄìTuring thesis- an idea was embroiled among the researchers. The idea to accumulate understanding from &lt;strong&gt;Neurobiology&lt;/strong&gt;, &lt;strong&gt;Information Theory&lt;/strong&gt;, &lt;strong&gt;Cybernetics&lt;/strong&gt; and many other branches of Natural science and engineering to build a &lt;strong&gt;electronic brain&lt;/strong&gt; or &lt;strong&gt;artificial brain&lt;/strong&gt;. Then, the perennial movement of Artificial Intelligence begun.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/2018-05-30/Artificial-Brain.png&quot; alt=&quot;my alt text&quot; /&gt;
    &lt;figcaption&gt; Artificial brain. &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;An artificial brain (or artificial mind) is software and hardware with cognitive
abilities similar to those of the animal or human brain. -
BBC News,2009&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;classical-ai&quot;&gt;Classical AI&lt;/h2&gt;
&lt;p&gt;Earlier/classical AI system are built on a list of formal, logistic and mathematical rules. Some such rules were Informed/Uninformed search strategies, Propositional Logic, First Order Logic, Planning, Heuristics functions, etc,.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/2018-05-30/knowledge-based-systems.jpg&quot; alt=&quot;kNR&quot; /&gt;
    &lt;figcaption&gt;Contains of Knowledge based Systems. &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;¬†&lt;/p&gt;

&lt;p&gt;We feted IBM‚Äôs Deep chess-playing system when it defeated world champion Garry Kasparov. But the system was completely rules and logic based system. If you know the board position, it is possible to know all you need to know to play the game, because given a certain board position, the possible moves are precisely defined and finite in number. Even though you may not know the particular move your opponent will make, you know that he will make a legal move. A system for defeating games like chess, tic-tac-toe, AlphaGO, etc can be built by programmer ahead of competition from a list of complete formal rules and logics. Thus classic AI is known as &lt;strong&gt;Knowledge based Intelligent System&lt;/strong&gt;.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/2018-05-30/tic-toc-toe.png&quot; alt=&quot;tic-tac-toe&quot; /&gt;
    &lt;figcaption&gt; Game tree of tic-tac-toe. Courtesy: Google DeepMind's AlphaGo: How it works
 &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;¬†&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/2018-05-30/tree-based.png&quot; alt=&quot;tree-based&quot; /&gt;
    &lt;figcaption&gt;Tree based search system for GO. Courtesy Google's Deepmind &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;¬†&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;problem&lt;/strong&gt; with the classical AI is: it‚Äôs inability to learn from environment or to extract and acquire their own knowledge from patterns of raw data provided to them. As they are bolstered by hand-coded knowledge.&lt;/p&gt;

&lt;p&gt;The list of Instance where classical AI fails:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Unable to extract information from real world for ex: camera images, typically in the form of a pixel array, and map them onto internal representations of the world&lt;/li&gt;
  &lt;li&gt;Classical AI models do not take the real world sufficiently into account. so, problem of generalization occurs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;machine-learning&quot;&gt;Machine Learning.&lt;/h2&gt;
&lt;p&gt;Machine Learning solves the problems classical AI by providing systems the ability to acquire their own knowledge by extracting information from real world data.&lt;/p&gt;

&lt;p&gt;Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed. Let me give you formal Book definition:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚ÄúA computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.‚Äù - Tom Mitchell‚Äôs Machine Learning Book&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A bit scary definition right? So, let me delineate it simply:
Let us say a machine is playing checker game.
The T, P, and E can be well defined by&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;E = the experience of playing many games of checkers&lt;/li&gt;
  &lt;li&gt;T = the task of playing checkers.&lt;/li&gt;
  &lt;li&gt;P = the probability that the program will win the next game.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With every experience ( E ) collected from environment or dataset or game, what decisions or tasks ( T ) the player has to take, so probability ( P ) of win is maximized.&lt;/p&gt;

&lt;p&gt;The performance of every machine learning algorithms depends on the &lt;strong&gt;representation&lt;/strong&gt; aka &lt;strong&gt;features&lt;/strong&gt; of the data they are given. This features helps AI to retain knowledge of patterns from raw data provided to them. The machine learning algorithm learns from data by correlating each features of data with various output.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/2018-05-30/ml-algorithm.png&quot; alt=&quot;ml-algorithm&quot; /&gt;
    &lt;figcaption&gt;Different types of Machine Learning Algorithm. &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;¬†&lt;/p&gt;

&lt;p&gt;It is not surprising that the choice of features has an colossal effect on the performance of machine learning algorithms. However, it is difficult to know what feature should be extracted for best performance of machine learning algorithm. For example, if MRI scan of the patient are given to Logistic Regression, it would not be able to make useful prediction as all the features are uniform in the form of pixel.&lt;/p&gt;

&lt;p&gt;Hence, the &lt;strong&gt;problem&lt;/strong&gt; with machine learning- it‚Äôs little bleak to use ML algorithm when we have difficult to extract a representation or best features to solve problem.&lt;/p&gt;

&lt;p&gt;The list of instance where machine Learning algorithm fails:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ML algorithms fails to give better result when datasets or representation of datasets is unstructured like images, audio, video.&lt;/li&gt;
  &lt;li&gt;It fails when there is no more data for learning purpose.&lt;/li&gt;
  &lt;li&gt;ML fail when, among the training examples, there are often similar inputs that are associated to different outputs.&lt;/li&gt;
  &lt;li&gt;Ml algorithms are designed to deal with noise in datasets at certain level but as more noise increase more difficult learning process becomes, which leads to bad accuracy.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-learning&quot;&gt;Deep Learning.&lt;/h2&gt;
</description>
        <pubDate>Wed, 30 May 2018 00:00:00 +0530</pubDate>
        <link>http://bikash-jaiswal.github.io/2018/05/30/Introduction-to-Artificial-Intelligence-and-its-branches.html</link>
        <guid isPermaLink="true">http://bikash-jaiswal.github.io/2018/05/30/Introduction-to-Artificial-Intelligence-and-its-branches.html</guid>
        
        <category>Artificial-Intelligence</category>
        
        
        <category>AI</category>
        
      </item>
    
      <item>
        <title>Sequential Models</title>
        <description>&lt;h2 id=&quot;recurrent-neural-networks&quot;&gt;Recurrent Neural Networks&lt;/h2&gt;
&lt;h3 id=&quot;why-sequence-models&quot;&gt;Why sequence Models&lt;/h3&gt;
&lt;h3 id=&quot;recurrent-neural-network-model&quot;&gt;Recurrent Neural Network Model&lt;/h3&gt;
&lt;h3 id=&quot;backpropagation-through-time&quot;&gt;Backpropagation through time&lt;/h3&gt;
&lt;h3 id=&quot;different-types-of-rnns&quot;&gt;Different types of RNNs&lt;/h3&gt;
&lt;h3 id=&quot;language-model-and-sequence-generation&quot;&gt;Language Model and sequence generation&lt;/h3&gt;
&lt;h3 id=&quot;sampling-novel-sequences&quot;&gt;Sampling novel sequences&lt;/h3&gt;
&lt;h3 id=&quot;vanishing-gradients-with-rnns&quot;&gt;Vanishing gradients with RNNS&lt;/h3&gt;
&lt;h3 id=&quot;gated-recurrent-unit-gru&quot;&gt;Gated Recurrent Unit (GRU)&lt;/h3&gt;
&lt;h3 id=&quot;bidirectional-rnn&quot;&gt;Bidirectional RNN&lt;/h3&gt;
&lt;h3 id=&quot;deep-rnns&quot;&gt;Deep RNNS&lt;/h3&gt;
</description>
        <pubDate>Wed, 30 May 2018 00:00:00 +0530</pubDate>
        <link>http://bikash-jaiswal.github.io/2018/05/30/Sequential-Model.html</link>
        <guid isPermaLink="true">http://bikash-jaiswal.github.io/2018/05/30/Sequential-Model.html</guid>
        
        <category>Deep-Learning</category>
        
        
        <category>Deep</category>
        
        <category>Learning</category>
        
        <category>Notes</category>
        
      </item>
    
      <item>
        <title>How to Structure Machine Learning Projects</title>
        <description>&lt;p&gt;Even after developing a model, We find that prediction accuracy is 90% but that isn‚Äôt good enough for production purpose because there are whole 10% error in prediction. So, we apply some technique to improve it like:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Collecting more diverse positive and negative training data&lt;/li&gt;
  &lt;li&gt;train the algorithm with gradient descent or use advance optimization algorithm like Adam.&lt;/li&gt;
  &lt;li&gt;Trying different network from smaller to bigger&lt;/li&gt;
  &lt;li&gt;also trying different regularization and dropout or changing the activation functions and number of hidden units.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-to-structure-machine-learning-projects&quot;&gt;How to Structure Machine Learning Projects&lt;/h2&gt;
&lt;p&gt;Applying above technique may not give always give desired result despite spending months on collecting data. Therefore, Some strategies is necessary which helps us in improving the accuracy of models.&lt;/p&gt;

&lt;h3 id=&quot;orthogonalization&quot;&gt;Orthogonalization&lt;/h3&gt;
&lt;p&gt;There are hundreds of parameters and hyperparameters to tune to increase the prediction accuracy but it‚Äôs cumbersome and tedious task to do. Here comes the role orthogonalization or orthogonality.&lt;/p&gt;

&lt;p&gt;The word orthogonal means ‚ÄúStatistically independent‚Äù. So,&lt;code class=&quot;highlighter-rouge&quot;&gt;Orthogonalization or orthogonality can be stated as a system design property that assures that modifying an instruction or a component of an algorithm will not create or propagate side effects  to  other components of the system.&lt;/code&gt; It becomes easier to verify the algorithms independently from one another, it reduces testing and development time.&lt;/p&gt;

&lt;p&gt;Let‚Äôs take to metaphorical example of old television and car steering.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/tv-car.jpg&quot; alt=&quot;metaphor&quot; /&gt;
    &lt;figcaption&gt; Metaphor for orthogonality &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;We can tune the picture on tv by varying the properties of knob of tv. Similarly, changing the steering of car can makes change in different direction to go.&lt;/p&gt;

&lt;p&gt;When a supervised learning system is design, these are the 4 assumptions that needs to be true and orthogonal.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Fit training set well in cost function
    &lt;ul&gt;
      &lt;li&gt;If it doesn‚Äôt fit well then use of a bigger neural network or use a better optimization algorithm.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Fit development set well on cost function
    &lt;ul&gt;
      &lt;li&gt;If it doesn‚Äôt fit well then use regularization or use bigger training set and use bigger training set.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Fit test set well on cost function
    &lt;ul&gt;
      &lt;li&gt;If it doesn‚Äôt fit well then use bigger Development set&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Performs well in real world
    &lt;ul&gt;
      &lt;li&gt;If it doesn‚Äôt fit well then change development set  or cost function.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;different-tuning-method-or-method-for-improving-our-model&quot;&gt;Different tuning method or method for improving our model.&lt;/h3&gt;
&lt;h4 id=&quot;using-a-single-number-evaluations-metric-ief1-score&quot;&gt;Using a single number evaluations metric. i.e.F1 score&lt;/h4&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/decision.png&quot; alt=&quot;decision&quot; /&gt;
    &lt;figcaption&gt; Confusion Matrix &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Precision&lt;/strong&gt; : Of all the images we predicted y=1, what fraction of it have cats?&lt;/p&gt;
&lt;figure&gt;
   &lt;div style=&quot;text-align:center&quot;&gt;
     &lt;img src=&quot;/assets/img/ml-strategies/precision.png&quot; alt=&quot;my alt text&quot; /&gt;
   &lt;/div&gt;
 &lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Recall&lt;/strong&gt; : Of all the images that actually have cats, what fraction of it did we correctly identifying have cats?&lt;/p&gt;
&lt;figure&gt;
   &lt;div style=&quot;text-align:center&quot;&gt;
     &lt;img src=&quot;/assets/img/ml-strategies/recall.png&quot; alt=&quot;my alt text&quot; /&gt;
   &lt;/div&gt;
 &lt;/figure&gt;

&lt;p&gt;Let‚Äôs compare 2 classifiers A and B used to evaluate if there are cat images:&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/evaluation-matrix.png&quot; alt=&quot;my alt text&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;In this case the evaluation metrics are precision and recall.&lt;/p&gt;

&lt;p&gt;For classifier A, there is a 95% chance that there is a cat in the image and a 90% chance that it has correctly detected a cat. Whereas for classifier B there is a 98% chance that there is a cat in the image and a 85% chance that it has correctly detected a cat.&lt;/p&gt;

&lt;p&gt;The problem with using precision/recall as the evaluation metric is that you are not sure which one is better since in this case, both of them have a good precision et recall. F1-score, a harmonic mean, combine both precision and recall.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/F1-score.png&quot; alt=&quot;my alt text&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;Classifier A is a better choice. F1-Score is not the only evaluation metric that can be use, the average, for
example, could also be an indicator of which classifier to use.&lt;/p&gt;

&lt;h4 id=&quot;satisficing-and-optimizing-metrics&quot;&gt;Satisficing and optimizing metrics.&lt;/h4&gt;
&lt;p&gt;There are different metrics to evaluate the performance of a classifier, they are called &lt;code class=&quot;highlighter-rouge&quot;&gt;evaluation matrices&lt;/code&gt;.
They can be categorized as &lt;code class=&quot;highlighter-rouge&quot;&gt;satisficing&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;optimizing&lt;/code&gt; matrices. It is important to note that these evaluation matrices must be evaluated on a training set, a development set or on the test set.&lt;/p&gt;

&lt;blockquote&gt;

  &lt;ul&gt;
    &lt;li&gt;optimizing ‚Äî&amp;gt; best accuracy&lt;/li&gt;
    &lt;li&gt;satisficing ‚Äî&amp;gt; running &amp;lt;= X ms.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/3table.png&quot; alt=&quot;my alt text&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;In this case, accuracy and running time are the evaluation matrices. Accuracy is the optimizing metric,
because you want the classifier to correctly detect a cat image as accurately as possible. The running time
which is set to be under 100 ms in this example, is the satisficing metric which mean that the metric has
to meet expectation set.&lt;/p&gt;

&lt;h4 id=&quot;traindevtest-set-distributions&quot;&gt;Train/dev/test set distributions&lt;/h4&gt;
&lt;p&gt;Setting up the training, development and test sets have a huge impact on productivity. It is important to
choose the development and test sets from the same distribution and it must be taken randomly from all
the data. &lt;code class=&quot;highlighter-rouge&quot;&gt;Test set should be big enough to give high confidence in the overall performance of your system.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;In dataset where data instances are few like below 100,000, researcher has used 80-20 rule.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/old-dist.png&quot; alt=&quot;my alt text&quot; /&gt;
    &lt;figcaption&gt; Strategy of distribution in machine learning &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;but because of generation Big Data, they have changed the rule to 98-1-1.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/new-dist.png&quot; alt=&quot;my alt text&quot; /&gt;
    &lt;figcaption&gt; Strategy of distribution in Deep Learning &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;h4 id=&quot;when-to-change-devtest-sets-and-metrics&quot;&gt;When to change dev/test sets and metrics&lt;/h4&gt;
&lt;p&gt;A cat classifier tries to find a great amount of cat images to show to cat loving users. The evaluation metric used is a classification error.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/error.png&quot; alt=&quot;my alt text&quot; /&gt;
    &lt;figcaption&gt; Strategy of distribution in machine learning &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;It seems that &lt;code class=&quot;highlighter-rouge&quot;&gt;Algorithm A is better than Algorithm B&lt;/code&gt; since there is only a 3% error, however for some reason, Algorithm A is letting through a lot of the pornographic images. Algorithm B has 5% error thus it classifies fewer images but it doesn‚Äôt have pornographic images. From a company‚Äôs point of view, as well as from a user acceptance point of view, &lt;code class=&quot;highlighter-rouge&quot;&gt;Algorithm B is actually a better
algorithm&lt;/code&gt;. The evaluation metric fails to correctly rank order preferences between algorithms. The evaluation metric or the development set or test set should be changed.&lt;/p&gt;

&lt;p&gt;The misclassification error metric can be written as a function as follow:&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/misclass.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;This function counts up the number of misclassified examples.
The problem with this evaluation metric is that it treats pornographic vs non-pornographic images equally. On way to change this evaluation metric is to add the weight term ùë§&lt;sup&gt;(ùëñ)&lt;/sup&gt;.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/more-weight.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The function becomes:&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/changed-equation.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Reminder&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define correctly an evaluation metric that helps better rank order classifiers&lt;/li&gt;
  &lt;li&gt;Optimize the evaluation metric&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;summary-of-orthogonalization&quot;&gt;Summary of orthogonalization&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;[x] Define a metric to evaluate a classifier&lt;/li&gt;
  &lt;li&gt;[x] Separately improve the metric to improve accuracy&lt;/li&gt;
  &lt;li&gt;[x] Change metric and/or dev/test set, if previous choosen  metric + dev/test fails.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;comparing-to-human-level-performance&quot;&gt;Comparing to human-level performance&lt;/h2&gt;
&lt;p&gt;Today, machine  learning  algorithms can  compete  with human - level  performance  since  they  are  more productive  and  more  feasible  in  a  lot of  application. Also,  the workflow  of  designing  and building  a machine learning system, is much more efficient than before.&lt;/p&gt;

&lt;p&gt;Moreover, some of the tasks that humans do are close  to ‚Äò‚Äôperfection‚Äô‚Äô, which is why machine learning tries to mimic human-level performance.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Bayes  optimal  error  is  defined  as  the  best  possible  error.  In  other  words, it  means that  any functions mapping from x to y can‚Äôt surpass a certain level of accuracy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/human vs model.png&quot; alt=&quot;misclassification&quot; /&gt;
    &lt;figcaption&gt; Performance
of humans and machine learning over time.&lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;Machine learning  progresses  slowly  when  it  surpasses human-level  performance.  One  of  the  reason  is that human-level  performance  can  be  close to  Bayes  optimal  error,  especially  for  natural  perception problem.&lt;/p&gt;

&lt;p&gt;Also, when  the  performance  of machine  learning  is  worse  than the  performance  of humans,  you  can improve it with different tools. They are harder to use once its surpasses human-level performance.&lt;/p&gt;

&lt;p&gt;These tools are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Get labeled data from humans&lt;/li&gt;
  &lt;li&gt;Gain insight from manual error analysis: Why did a person get this right?&lt;/li&gt;
  &lt;li&gt;Better analysis of bias/variance&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;avoidable-bias&quot;&gt;Avoidable bias&lt;/h4&gt;
&lt;p&gt;By knowing what the human-level performance is, it is possible to tell when a training set is performing well or not.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/avoidable-bias.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;In this case, the human level error as a proxy for Bayes error since humans are good to identify images.If you want  to  improve  the performance  of  the  training  set  but  you  can‚Äôt do better than the Bayes error otherwise the training set is overfitting. By knowing the Bayes error, it is easier to focus on whether bias or variance avoidance tactics will improve the performance of the model.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Scenario A:&lt;/code&gt; There is a &lt;code class=&quot;highlighter-rouge&quot;&gt;7%&lt;/code&gt; gap between the performance of the training set and the human
level error. It means that the algorithm is n‚Äôt fitting well with the training set since the target is around 1%. To resolve the issue, we use bias reduction technique such as training a bigger neural network or running the training set longer.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Scenario B:&lt;/code&gt; The  training  set  is  doing  good  since  there  is  only a &lt;code class=&quot;highlighter-rouge&quot;&gt;0.5%&lt;/code&gt; difference with the  human  level error.  &lt;code class=&quot;highlighter-rouge&quot;&gt;The difference between the training set and the human level error is called avoidable bias&lt;/code&gt;. The focus here is to reduce the variance since the difference between the training error and the development error is 2%. To resolve the issue, we use variance reduction technique such as regularization or have a bigger training set&lt;/p&gt;

&lt;h4 id=&quot;understanding-human-level-performance&quot;&gt;Understanding human-level performance&lt;/h4&gt;
&lt;p&gt;Human-level error gives an estimate of Bayes error.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example 1: Medical image classification&lt;/strong&gt;
This is an example of a medical image classification in which the input is a radiology image and the output is a diagnosis classification decision.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/scenario-A.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The definition of human-level error depends on the purpose of the analysis, in this case, by definition the Bayes error is lower or equal to 0.5%.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example 2: Error analysis&lt;/strong&gt;&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/error-analysis.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Scenario A&lt;/code&gt;
In this case, the choice of human-level performance doesn‚Äôt have an impact. The avoidable bias is between 4%-4.5% and the variance is 1%. Therefore, the focus should be on bias reduction technique.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Scenario B&lt;/code&gt;
In this case, the choice of human-level performance doesn‚Äôt have an impact. The avoidable bias is between 0%-0.5% and the variance is 4%. Therefore, the focus should be on variance reduction technique.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Scenario C&lt;/code&gt;
In this case, the estimate for Bayes error has to be 0.5% since you can‚Äôt go lower than the human-level performance otherwise the training set is overfitting. Also, the avoidable bias is 0.2% and the variance is 0.1%. Therefore, the focus should be on bias reduction technique.&lt;/p&gt;

&lt;p&gt;Summary of bias/variance with human-level performance&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Human - level error ‚Äì proxy for Bayes error&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If the difference between human-level error and the training error is bigger than the difference between the training error and the development error. The focus should be on bias reduction technique&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If the difference between training error and the development error is bigger than the difference between the human-level error and the training error. The focus should be on variance reduction technique&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;surpassing-human-level-performance&quot;&gt;Surpassing human-level Performance&lt;/h4&gt;
&lt;p&gt;Example1 : classification task&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/surpassing.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Scenario A:&lt;/code&gt;
In this case, the Bayes error is 0.5%, therefore the available bias is 0.1% et the variance is 0.2%.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Scenario B:&lt;/code&gt;
In this case, there is not enough information to know if bias reduction or variance reduction has to be done on the algorithm. It doesn‚Äôt mean that the model cannot be improve, it means that the conventional ways to know if bias reduction or variance reduction are not working in this case.&lt;/p&gt;

&lt;p&gt;There are many problems where machine learning significantly surpasses human-level performance, especially with structured data:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Online advertising&lt;/li&gt;
  &lt;li&gt;Product recommendations&lt;/li&gt;
  &lt;li&gt;Logistics (predicting transit time)&lt;/li&gt;
  &lt;li&gt;Loan approvals&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;improving-model-performance&quot;&gt;Improving model performance&lt;/h4&gt;

&lt;p&gt;There are &lt;code class=&quot;highlighter-rouge&quot;&gt;2 fundamental assumptions of supervised learning&lt;/code&gt;. The first one is to &lt;code class=&quot;highlighter-rouge&quot;&gt;have a low avoidable bias&lt;/code&gt; which means that the training set fits well. The second one is to &lt;code class=&quot;highlighter-rouge&quot;&gt;have a low or acceptable variance&lt;/code&gt; which means that the training set performance generalizes well to the development set and test set.&lt;/p&gt;

&lt;p&gt;If the difference between human-level error and the training error is bigger than the difference between the training error and the development error, the focus should be on bias reduction technique which are training a bigger model, training longer or change the neural networks architecture or try various hyperparameters search.&lt;/p&gt;

&lt;p&gt;If the difference between training error and the development error is bigger than the difference between the human-level error and the training error, the focus should be on variance reduction technique which are bigger data set, regularization or change the neural networks architecture or try various hyperparameters search.&lt;/p&gt;

&lt;h4 id=&quot;summary&quot;&gt;Summary&lt;/h4&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/ml-strategies/improving.png&quot; alt=&quot;misclassification&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;error-analysis&quot;&gt;Error analysis&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Error Analysis&lt;/code&gt;: The process of manually examining mistakes, when learning algorithms do not give the performance of a human level. It helps in finding insight on what to do next.&lt;/p&gt;

&lt;p&gt;For Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In the cat classification example, if you have 10% error on your dev set and you want to decrease the error.&lt;/li&gt;
  &lt;li&gt;You discovered that some of the mislabeled data are dog pictures that look like cats. Should you try to make your cat classifier do better on dogs (this could take some weeks)?
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Error analysis approach&lt;/code&gt;:
        &lt;ul&gt;
          &lt;li&gt;Get 100 mislabeled dev set examples at random.&lt;/li&gt;
          &lt;li&gt;Count up how many are dogs.&lt;/li&gt;
          &lt;li&gt;if 5 of 100 are dogs then training your classifier to do better on dogs will decrease your error up to 9.5% (called ceiling), which can be too little.&lt;/li&gt;
          &lt;li&gt;if 50 of 100 are dogs then you could decrease your error up to 5%, which is reasonable and you should work on that.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Based on the last example, error analysis helps you to analyze the error before taking an action that could take lot of time with no need. Sometimes, you can evaluate multiple error analysis ideas in parallel and choose the best idea. Create a spreadsheet to do that and decide, e.g.:&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
   &lt;div style=&quot;text-align:center&quot;&gt;
     &lt;img src=&quot;/assets/img/ml-strategies/table-strategies.png&quot; alt=&quot;misclassification&quot; /&gt;
   &lt;/div&gt;
 &lt;/figure&gt;

&lt;p&gt;This quick counting procedure, which you can often do in, at most, small numbers of hours can really help you make much better prioritization decisions, and understand how promising different approaches are to work on.&lt;/p&gt;

&lt;h4 id=&quot;carrying-out-error-analysis&quot;&gt;Carrying out error analysis&lt;/h4&gt;
&lt;h4 id=&quot;cleaning-up-incorrectly-labeled-data&quot;&gt;Cleaning up incorrectly labeled data&lt;/h4&gt;
&lt;h4 id=&quot;build-your-first-system-quickly-then-iterate&quot;&gt;Build your first system quickly, then iterate&lt;/h4&gt;

&lt;h3 id=&quot;mismatched-training-and-devtest-sets&quot;&gt;Mismatched training and dev/test sets&lt;/h3&gt;
&lt;h4 id=&quot;bias-and-variance-with-mismatched-data-distributions&quot;&gt;Bias and Variance with Mismatched data distributions.&lt;/h4&gt;
&lt;h4 id=&quot;addressing-data-mismatched&quot;&gt;Addressing data Mismatched&lt;/h4&gt;

&lt;h3 id=&quot;learning-from-multiple-tasks&quot;&gt;Learning from multiple tasks&lt;/h3&gt;
&lt;h4 id=&quot;transfer-learning&quot;&gt;Transfer Learning&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Apply the knowledge you took in a task A and apply it in another task B.&lt;/li&gt;
  &lt;li&gt;For example, you have trained a cat classifier with a lot of data, you can use the part of the trained NN it to solve x-ray classification problem.&lt;/li&gt;
  &lt;li&gt;To do transfer learning, delete the last layer of NN and it‚Äôs weights and:&lt;/li&gt;
  &lt;li&gt;Option 1: if you have a small data set - keep all the other weights as a fixed weights. Add a new last layer(-s) and initialize the new layer weights and feed the new data to the NN and learn the new weights.&lt;/li&gt;
  &lt;li&gt;Option 2: if you have enough data you can retrain all the weights.&lt;/li&gt;
  &lt;li&gt;Option 1 and 2 are called &lt;code class=&quot;highlighter-rouge&quot;&gt;fine-tuning&lt;/code&gt; and training on task A called &lt;code class=&quot;highlighter-rouge&quot;&gt;pretraining&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;When transfer learning make sense:
    &lt;ul&gt;
      &lt;li&gt;Task A and B have the same input X (e.g. image, audio).&lt;/li&gt;
      &lt;li&gt;You have a lot of data for the task A you are transferring from and relatively less data for the task B your transferring to.&lt;/li&gt;
      &lt;li&gt;Low level features from task A could be helpful for learning task B.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;multi-task-learning&quot;&gt;Multi-task Learning&lt;/h4&gt;

&lt;h3 id=&quot;end-to-end-deep-learning&quot;&gt;End-to-end deep Learning&lt;/h3&gt;
&lt;h4 id=&quot;what-is-end-to-end-deep-learning&quot;&gt;What is end-to-end deep learning?&lt;/h4&gt;
&lt;h4 id=&quot;wheteher-to-use-end-to-end-deep-learning&quot;&gt;Wheteher to use end-to-end deep Learning&lt;/h4&gt;
</description>
        <pubDate>Fri, 20 Apr 2018 00:00:00 +0530</pubDate>
        <link>http://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html</link>
        <guid isPermaLink="true">http://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html</guid>
        
        <category>Deep-Learning</category>
        
        
        <category>Deep</category>
        
        <category>Learning</category>
        
        <category>Notes</category>
        
      </item>
    
      <item>
        <title>Practical aspects of Deep Learning</title>
        <description>&lt;p&gt;After implementation of a neural network, we have gained enough vim to better understand the black box of Deep Learning and to learn all the practical aspects of making our neural network work even better. We are going to learn various tricks or technique like:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Hyperparameter tuning&lt;/li&gt;
  &lt;li&gt;Setting the datasets&lt;/li&gt;
  &lt;li&gt;Optimization algorithm- makes learning algorithm to learn in a reasonable time&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;practical-aspects-of-deep-learning&quot;&gt;Practical aspects of Deep Learning&lt;/h2&gt;
&lt;p&gt;When we start to solve a new problem in using deep learning, we can never decide earlier what to choose like - what learning rate? how many hidden layers? which activation functions to choose and for which layers? To find the answer we have to follow iterative process of &lt;code class=&quot;highlighter-rouge&quot;&gt;Idea ---&amp;gt; code ---&amp;gt; Experiment&lt;/code&gt;. Even seasoned deep learning expert find it almost impossible to correctly guess the best choice of hyperparameters the very first time.&lt;/p&gt;

&lt;h3 id=&quot;setting-up-your-machine-learning-application&quot;&gt;Setting up your Machine Learning Application&lt;/h3&gt;
&lt;h5 id=&quot;train--dev--test-sets&quot;&gt;1. Train / Dev / Test sets&lt;/h5&gt;
&lt;p&gt;Your data will be split into three parts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Training set. (Has to be the largest set)&lt;/li&gt;
  &lt;li&gt;Development or ‚Äúdev‚Äù set.&lt;/li&gt;
  &lt;li&gt;Testing set.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
  &lt;img src=&quot;/assets/img/ml-strategies/new-dist.png&quot; alt=&quot;my alt text&quot; /&gt;
      &lt;figcaption&gt; Strategy of distribution in Deep Learning &lt;/figcaption&gt;
    &lt;/div&gt;
  &lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;Generally, we have give just Training set and Test set in real life and also in Kaggle competitions. To construct the development set use following technique:&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Test set size = 10,000,000, then split like below&lt;/li&gt;
    &lt;li&gt;Test set size = index from 1 - 9,900,000 i.e. 98% of original test set&lt;/li&gt;
    &lt;li&gt;Development set = index from 9,900,001 - 10,000,000 i.e. 1% of original test sets.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;You will try to build a model upon training set then try to optimize hyperparameters on dev set as much as possible. Then after your model is ready you try and evaluate the testing set.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Make sure the dev and test set are coming from the same distribution&lt;/code&gt;. Suppose training pictures is from the web and the dev/test pictures are from users cell phone they will mismatch. It is better to make sure that dev and test set are from the same distribution.&lt;/p&gt;

&lt;p&gt;For more knowledge on Train/dev/test set distributions topic follow &lt;a href=&quot;https://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html&quot;&gt;Machine Learning Strategy In Deep Learning&lt;/a&gt; 3rd course in Deep learning specialization.&lt;/p&gt;

&lt;h5 id=&quot;bias---variance&quot;&gt;2. Bias - Variance&lt;/h5&gt;

&lt;p&gt;One of the quick question to evaluate someone‚Äôs technical skill on Machine Learning or Deep Learning is to ask him/her about bias/ Variance and Overfitting and Underfitting.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;It is simple and vital topic but difficult to master.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;More information on the problem of overfitting and underfitting can be found on &lt;a href=&quot;https://github.com/bikash-jaiswal/Machine-Learning-Notes/blob/master/3.a.The-problem-of-overfitting.md&quot;&gt;The problem of Underfitting&lt;/a&gt; course for Machine learning taught by Andrew Ng in &lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot;&gt;coursera&lt;/a&gt;.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/bias-variance.png&quot; alt=&quot;Bias-variance&quot; /&gt;
    &lt;figcaption&gt; Bias-Variance &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Overfitting&lt;/strong&gt; : models with overfitting problem has good performance on the training data, poor generliazation to other data. It is usually caused by a complicated function that creates a lot of unnecessary curves and angles unrelated to the data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Underfitting&lt;/strong&gt;: models that can neither model the training data nor generalize to new data. It is usually caused by a function that is too simple or uses too few features.&lt;/p&gt;

&lt;p&gt;Analysis Bias and Variance with training error rate and validation error value. Assumption made for below comparison: human error = 0%&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;High variance (overfitting):
    &lt;ul&gt;
      &lt;li&gt;Training error: 1%&lt;/li&gt;
      &lt;li&gt;Dev error: 11%&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;High Bias (underfitting):
    &lt;ul&gt;
      &lt;li&gt;Training error: 15%&lt;/li&gt;
      &lt;li&gt;Dev error: 14%&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;High Bias (underfitting) &amp;amp;&amp;amp; High variance (overfitting) :
    &lt;ul&gt;
      &lt;li&gt;Training error: 15%&lt;/li&gt;
      &lt;li&gt;Test error: 30%&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Best:
    &lt;ul&gt;
      &lt;li&gt;Training error: 0.5%&lt;/li&gt;
      &lt;li&gt;Test error: 1%&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To know more about human level performance see &lt;a href=&quot;https://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html&quot;&gt;Machine Learning Strategy In Deep Learning&lt;/a&gt; 3rd course in Deep learning specialization.&lt;/p&gt;

&lt;h5 id=&quot;basic-recipe-for-machine-learning&quot;&gt;3. Basic Recipe for Machine Learning&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;If your algorithm has a high bias:
    &lt;ul&gt;
      &lt;li&gt;Try to make your NN bigger (size of hidden units, number of layers)&lt;/li&gt;
      &lt;li&gt;Try a different model that is suitable for your data.
Try to run it longer.
Different (advanced) optimization algorithms.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If your algorithm has a high variance:
    &lt;ul&gt;
      &lt;li&gt;More data.&lt;/li&gt;
      &lt;li&gt;Try regularization.&lt;/li&gt;
      &lt;li&gt;Try a different model that is suitable for your data.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You should try the previous two points until you have a low bias and low variance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In the older days before deep learning, there was a ‚ÄúBias/variance trade-off‚Äù. But because now you have more options/tools for solving the bias and variance problem its really helpful to use deep learning.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Training a bigger neural network never hurts.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;regularizing-your-neural-network&quot;&gt;Regularizing your neural network&lt;/h3&gt;
&lt;p&gt;As of solution listed in case of high variance, getting more data is not always feasible in every case of application, nevertheless, trying regularization is always possible.&lt;/p&gt;

&lt;h5 id=&quot;applying-regularization-in-logistic-regression&quot;&gt;Applying regularization in logistic regression&lt;/h5&gt;
&lt;p&gt;Here, &lt;code class=&quot;highlighter-rouge&quot;&gt;||W|| = sum of absolute values of all weight&lt;/code&gt; and the cost function of logistic regression is &lt;code class=&quot;highlighter-rouge&quot;&gt;J(w,b) = (1/m) * Sum(L(y(i),y'(i)))&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda&lt;/code&gt; is  regularization parameter (another hyperparameter).&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/regularization-LR.png&quot; alt=&quot;regularization in Logistic regression&quot; /&gt;
    &lt;figcaption&gt; Regularization in Logistic Regression &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;Though &lt;code class=&quot;highlighter-rouge&quot;&gt;L2 regularization is used much&lt;/code&gt; despite &lt;code class=&quot;highlighter-rouge&quot;&gt;L1 regularization&lt;/code&gt;, people thinks, can help with compressing the model as it makes &lt;code class=&quot;highlighter-rouge&quot;&gt;W&lt;/code&gt; sparse by setting some of W‚Äôs value zero and also uses less memory to store the model.&lt;/p&gt;

&lt;h5 id=&quot;regularization-in-neural-network&quot;&gt;Regularization in Neural Network.&lt;/h5&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/regu-nn.png&quot; alt=&quot;regularization in Neural network&quot; /&gt;
    &lt;figcaption&gt; Regularization in Neural Network &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Update the gradient of &lt;code class=&quot;highlighter-rouge&quot;&gt;W&lt;/code&gt; by:
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dW[l] = (from backpropagation) +  lambda/m * W[l] &lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;W[l] = W[l] -lr*dW[l]&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
w[l] = w[l] - lr * dw[l]
     = w[l] - lr * ((from back propagation) + lambda/m * w[l])
     = w[l] - (lr*lambda/m) * w[l] - lr * (from back propagation)
     = (1 - (lr*lambda)/m) * w[l] - lr * (from back propagation)

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The new term &lt;code class=&quot;highlighter-rouge&quot;&gt;(1 - (learning_rate*lambda)/m) * w[l]&lt;/code&gt; causes the weight to decay in proportion to its size.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(lambda/2m) * Sum((||W[l]||^2)&lt;/code&gt;  penalizes the weight matrices from being too large.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;how-does-regularization-prevent-overfitting&quot;&gt;How does regularization prevent overfitting&lt;/h5&gt;
&lt;p&gt;Some Intuition that can help us in finding why and how does regularization help with overfitting and reducing variance problems?&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Intuition I&lt;/code&gt;: If regularization parameter &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda&lt;/code&gt; is too big.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a lot of w‚Äôs will be close to zeros which will make the Neural network simpler (you can think of it as it would behave closer to logistic regression with more hidden layers).&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
    &lt;div style=&quot;text-align:center&quot;&gt;
      &lt;img src=&quot;/assets/img/practical-aspect/simpler-nn.png&quot; alt=&quot;simpler-nn&quot; /&gt;
      &lt;figcaption&gt; NN when lambda is too large &lt;/figcaption&gt;
    &lt;/div&gt;
  &lt;/figure&gt;
&lt;ul&gt;
  &lt;li&gt;If lambda is good enough: It will just reduce some weights that makes the neural network overfit.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Intuition II with tanh function&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If lambda is too large, w‚Äôs will be small (close to zero) - will use the linear part of the tanh activation function, so we will go from non linear activation to roughly linear which would make the NN a roughly linear classifier.&lt;/li&gt;
  &lt;li&gt;If lambda good enough it will just make some of tanh activations roughly linear which will prevent overfitting.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Implementation tip&lt;/code&gt;&lt;/strong&gt;: If you implement gradient descent, one of the steps to debug gradient descent is to plot the cost function (J) as a function of the number of iterations of gradient descent and you want to see that the cost function J &lt;strong&gt;decreases monotonically&lt;/strong&gt; after every elevation of gradient descent with regularization. If you plot the old definition of J (no regularization) then you might not see it decrease monotonically.
monotonically decreassing&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/monotonically decreassing.png&quot; alt=&quot;monotonically decreassing&quot; /&gt;
    &lt;figcaption&gt;monotonically decreassing
 &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;h5 id=&quot;dropout-technique&quot;&gt;Dropout technique&lt;/h5&gt;
&lt;p&gt;Dropout	is	a	technique	used	to	improve	over-fit	on	neural	networks,	we	should	use	Dropout	along with	other	techniques	like	L2	Regularization.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/dropout.png&quot; alt=&quot;Dropout&quot; /&gt;
    &lt;figcaption&gt;Dropout
 &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Dropout Intuition:&lt;/code&gt; Go through each of the layers of the network and set some probability for eliminating a node in neural network.  So, we end up with a much smaller, really much diminished network.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Implementation of Dropout aka Inverted dropout&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;keep_prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 0 &amp;lt;= keep_prob &amp;lt;=1&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# the generated number that are less than 0.8 will be dropped.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#80% stay, 20% dropped&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# this code is only for layer 3&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;d3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keep_prob&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# keep only the values in d3&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# increase a3 to not reduce the expected value of output&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# (ensures that the expected value of a3 remains the same)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# to solve the scaling problem&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keep_prob&lt;/span&gt;      
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;If there are 50 neuron than 10 neurons will be shut off&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vector d[l] is used for forward and back propagation and is the same for them, but it is different for each iteration (pass) or training example.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;At test time we don‚Äôt use dropout. If you implement dropout at test time - it would add noise to predictions.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;understanding-dropout&quot;&gt;Understanding Dropout&lt;/h5&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Intuition:&lt;/code&gt; Dropout randomly knocks out units in your network. So it‚Äôs as if on every iteration you‚Äôre working with a smaller NN, and so using a smaller NN seems like it should have a regularizing effect.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Another Intution:&lt;/code&gt; can‚Äôt rely on any one feature, so have to spread out weights.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It‚Äôs possible to show that dropout has a similar effect to L2 regularization.&lt;/li&gt;
  &lt;li&gt;Dropout can have different keep_prob per layer.&lt;/li&gt;
  &lt;li&gt;The input layer dropout has to be near 1 (or 1 - no dropout) because you don‚Äôt want to eliminate a lot of features.&lt;/li&gt;
  &lt;li&gt;If you‚Äôre more worried about some layers overfitting than others, you can set a lower keep_prob for some layers than others. The downside is, this gives you even more hyperparameters to search for using cross-validation. One other alternative might be to have some layers where you apply dropout and some layers where you don‚Äôt apply dropout and then just have one hyperparameter, which is a keep_prob for the layers for which you do apply dropouts.&lt;/li&gt;
  &lt;li&gt;A lot of researchers are using dropout with Computer Vision (CV) because they have a very big input size and almost never have enough data, so overfitting is the usual problem. And dropout is a regularization technique to prevent overfitting.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A downside of dropout is that the cost function J is not well defined and it will be hard to debug (plot J by iteration).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;To solve that you‚Äôll need to turn off dropout, set all the &lt;code class=&quot;highlighter-rouge&quot;&gt;keep_probs&lt;/code&gt; to 1, and then run the code and check that it monotonically decreases J and then turn on the dropouts again.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;wheretousedropoutlayers&quot;&gt;Where	to	use	Dropout	layers&lt;/h5&gt;
&lt;p&gt;Normally	some	deep	learning	models use Dropout on	the	fully	connected	layers,	but	is	also	possible to	use	dropout	after	the	max-pooling	layers,	creating	some	kind	of	image	noise	augmentation.&lt;/p&gt;

&lt;h5 id=&quot;other-regularization-methods&quot;&gt;Other regularization methods&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Data augmentation:
    &lt;ul&gt;
      &lt;li&gt;For example in a computer vision data:
        &lt;ul&gt;
          &lt;li&gt;You can flip all your pictures horizontally this will give you m more data instances.&lt;/li&gt;
          &lt;li&gt;You could also apply a random position and rotation to an image to get more data.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;For example in OCR, you can impose random rotations and distortions to digits/letters.&lt;/li&gt;
      &lt;li&gt;New data obtained using this technique isn‚Äôt as good as the real independent data, but still can be used as a regularization technique.&lt;/li&gt;
    &lt;/ul&gt;
    &lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/data-augment.png&quot; alt=&quot;data augmentation&quot; /&gt;
    &lt;figcaption&gt;Data Augmentation
 &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
  &lt;/li&gt;
  &lt;li&gt;Early stopping:
    &lt;ul&gt;
      &lt;li&gt;In this technique we plot the training set and the dev set cost together for each iteration. At some iteration the dev set cost will stop decreasing and will start increasing.&lt;/li&gt;
      &lt;li&gt;We will pick the point at which the training set error and dev set error are best (lowest training cost with lowest dev cost).&lt;/li&gt;
      &lt;li&gt;We will take these parameters as the best parameters.&lt;/li&gt;
    &lt;/ul&gt;
    &lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/early-stopping.png&quot; alt=&quot;Early stopping&quot; /&gt;
    &lt;figcaption&gt;Early stopping
 &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Advantages:&lt;/code&gt; you don‚Äôt need to search a hyperparameter like in other regularization approaches (like lambda in L2 regularization).&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Disadvantages:&lt;/code&gt; Early stopping simultaneously tries to minimize the cost function and not to overfit which contradicts the orthogonalization approach (will be discussed further). So, use L2 regularization.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Model Ensembles:
    &lt;ul&gt;
      &lt;li&gt;Algorithm:
        &lt;ul&gt;
          &lt;li&gt;Train multiple independent models.&lt;/li&gt;
          &lt;li&gt;At test time average their results.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;It can get you extra 2% performance.&lt;/li&gt;
      &lt;li&gt;It reduces the generalization error.&lt;/li&gt;
      &lt;li&gt;You can use some snapshots of your NN at the training ensembles them and take the results.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;setting-up-your-optimization-problem&quot;&gt;Setting up your optimization problem&lt;/h3&gt;

&lt;h5 id=&quot;normalizing-input&quot;&gt;Normalizing input&lt;/h5&gt;
&lt;p&gt;When training a neural network, one of the techniques that will speed up training is if we have normalized our inputs.&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/normalizing.png&quot; alt=&quot;Early stopping&quot; /&gt;
    &lt;figcaption&gt; Normalization of data
 &lt;/figcaption&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Normalization are going on these steps:
    &lt;ul&gt;
      &lt;li&gt;First get the mean of the training set: &lt;code class=&quot;highlighter-rouge&quot;&gt;mean = (1/m) * sum(x(i))&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Then, subtract the mean from each input: &lt;code class=&quot;highlighter-rouge&quot;&gt;X = X - mean&lt;/code&gt; to make your inputs centered around 0.&lt;/li&gt;
      &lt;li&gt;Atlast, get the variance of the training set: &lt;code class=&quot;highlighter-rouge&quot;&gt;variance = (1/m) * sum(x(i)^2)&lt;/code&gt;and normalize the variance. &lt;code class=&quot;highlighter-rouge&quot;&gt;X /= variance&lt;/code&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Note:&lt;/code&gt; These steps should be applied to all training, dev, and testing sets (but using mean and variance of the train set).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Why normalize?
    &lt;ul&gt;
      &lt;li&gt;If we don‚Äôt normalize the inputs our cost function will be deep and its shape will be inconsistent (elongated) then optimizing it will take a long time.&lt;/li&gt;
      &lt;li&gt;But if we normalize it the opposite will occur. The shape of the cost function will be consistent (look more symmetric like circle in 2D example) and we can use a larger learning rate alpha - the optimization will be faster.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;vanishingexploding-gradients&quot;&gt;Vanishing/Exploding gradients&lt;/h5&gt;
&lt;blockquote&gt;
  &lt;p&gt;Vanishing and Exploding gradients ‚Äî-&amp;gt; During training when gradient becomes either too small or too big respectively.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Consider this 9-layer neural network just after it was initialized.&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/9-layer.png&quot; alt=&quot;vanishing&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;To understand the problem, suppose that we have a deep neural network with number of layers L, and all the activation functions are linear(identity matrix)  i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;g(z)=z&lt;/code&gt; and each&lt;code class=&quot;highlighter-rouge&quot;&gt;b = 0&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Then the output activation is: Y = W&lt;sup&gt;L&lt;/sup&gt;W&lt;sup&gt;L-1&lt;/sup&gt;W[1]‚Ä¶..W&lt;sup&gt;2&lt;/sup&gt;W&lt;sup&gt;1&lt;/sup&gt;X where L=10 and W&lt;sup&gt;1&lt;/sup&gt;,W&lt;sup&gt;2&lt;/sup&gt;,‚Ä¶,W&lt;sup&gt;L-1&lt;/sup&gt; are all matrices of size (2,2) because layers [1] to [L-1] have 2 neurons and receive 2 inputs.&lt;/p&gt;

&lt;p&gt;Consider the case where every weight is initialized slightly larger than the identity matrix.&lt;/p&gt;

&lt;h6 id=&quot;exploding-gradients&quot;&gt;Exploding Gradients:&lt;/h6&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;This simplifies to y‚Äô=W&lt;sup&gt;L&lt;/sup&gt;1.5&lt;sup&gt;L‚àí1&lt;/sup&gt;X and the values of the activation a&lt;sup&gt;l&lt;/sup&gt; increase exponentially with l. When these activations are used in backward propagation, this leads to the exploding gradient problem.&lt;/p&gt;

&lt;h6 id=&quot;vanishing-gradients&quot;&gt;Vanishing gradients&lt;/h6&gt;
&lt;p&gt;Similarly, consider the case where every weight is initialized slightly smaller than the identity matrix&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;This simplifies to y‚Äô=W&lt;sup&gt;L&lt;/sup&gt;0.5&lt;sup&gt;L‚àí1&lt;/sup&gt;X and the values of the activation a&lt;sup&gt;l&lt;/sup&gt; decreases exponentially with l. When these activations are used in backward propagation, this leads to the vanishing gradient problem.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Recently Microsoft trained 152 layers (ResNet)! which is a really big number. With such a deep neural network, if your activations or gradients increase or decrease exponentially as a function of L, then these values could get really big or really small. And this makes training difficult, especially if your gradients are exponentially smaller than L, then gradient descent will take tiny little steps. It will take a long time for gradient descent to learn anything.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;weight-initialization&quot;&gt;Weight initialization&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;A partial solution to the Vanishing / Exploding gradients in NN is better or more careful choice of the random initialization of weights&lt;/li&gt;
  &lt;li&gt;In a single neuron (Perceptron model): Z = w&lt;sup&gt;1&lt;/sup&gt;x&lt;sup&gt;1&lt;/sup&gt; + w&lt;sup&gt;2&lt;/sup&gt;x&lt;sup&gt;2&lt;/sup&gt; + ‚Ä¶ + w&lt;sup&gt;n&lt;/sup&gt;x&lt;sup&gt;n&lt;/sup&gt;
    &lt;ul&gt;
      &lt;li&gt;So if &lt;code class=&quot;highlighter-rouge&quot;&gt;n_x&lt;/code&gt; is large we want W‚Äôs to be smaller to not explode the cost.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;So it turns out that we need the variance which equals &lt;code class=&quot;highlighter-rouge&quot;&gt;1/n_x&lt;/code&gt; to be the range of W‚Äôs
So lets say when we initialize W‚Äôs like this (better to use with tanh activation):&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Maintaining the value of the variance of the input and the output of every layer guarantees no exploding/vanishing gradient(&lt;code class=&quot;highlighter-rouge&quot;&gt;ReLU + Weight Initialization with variance&lt;/code&gt;). The recommended initialization is Xavier initialization (or one of its derived methods), for every layer &lt;code class=&quot;highlighter-rouge&quot;&gt;l&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;or variation of this (Bengio et al.):&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;or Setting initialization part inside sqrt to 2/n[l-1] for ReLU is better&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h5 id=&quot;numerical-approximation-in-gradients&quot;&gt;Numerical approximation in gradients&lt;/h5&gt;
&lt;p&gt;How to make check the implementation of your Back propagation is correct?&lt;/p&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/numerical.png&quot; alt=&quot;vanishing&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NOTE:&lt;/code&gt; Gradient checking approximates the gradients and is very helpful for finding the errors in your backpropagation implementation but it‚Äôs slower than gradient descent (so use only for debugging).&lt;/p&gt;

&lt;h5 id=&quot;gradient-checking&quot;&gt;Gradient checking&lt;/h5&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/gradient-check.png&quot; alt=&quot;vanishing&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;ul&gt;
  &lt;li&gt;First take &lt;code class=&quot;highlighter-rouge&quot;&gt;W[1],b[1],...,W[L],b[L]&lt;/code&gt; and reshape into one big vector (theta)&lt;/li&gt;
  &lt;li&gt;Then take &lt;code class=&quot;highlighter-rouge&quot;&gt;dW[1],db[1],...,dW[L],db[L]&lt;/code&gt; into one big vector (d_theta&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# small number&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;d_theta_approx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Finally check &lt;code class=&quot;highlighter-rouge&quot;&gt;(||d_theta_approx - d_theta||) / (||d_theta_approx||+||d_theta||)&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;if it is &amp;lt; 10^-7 - great, very likely the backpropagation implementation is correct&lt;/li&gt;
      &lt;li&gt;if around 10^-5 - can be OK, but need to inspect if there are no particularly big values in &lt;code class=&quot;highlighter-rouge&quot;&gt;d_theta_approx - d_theta vector&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;if it is &amp;gt;= 10^-3 - bad, probably there is a bug in back propagation implementation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;gradient-checking-implementation-notes&quot;&gt;Gradient checking implementation notes&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Don‚Äôt use the gradient checking algorithm at training time because it‚Äôs very slow.&lt;/li&gt;
  &lt;li&gt;Use gradient checking only for debugging.&lt;/li&gt;
  &lt;li&gt;If algorithm fails grad check, look at components to try to identify the bug.&lt;/li&gt;
  &lt;li&gt;Don‚Äôt forget to add lamda/(2m) * sum(W[l]) to J if you are using L1 or L2 regularization.&lt;/li&gt;
  &lt;li&gt;Gradient checking doesn‚Äôt work with dropout because J is not consistent.
    &lt;ul&gt;
      &lt;li&gt;You can first turn off dropout &lt;code class=&quot;highlighter-rouge&quot;&gt;(set keep_prob = 1.0)&lt;/code&gt;, run gradient checking and then turn on dropout again.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Run gradient checking at random initialization and train the network for a while maybe there‚Äôs a bug which can be seen when w‚Äôs and b‚Äôs become larger (further from 0) and can‚Äôt be seen on the first iteration (when w‚Äôs and b‚Äôs are very small).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;different-optimization-algorithms&quot;&gt;Different Optimization algorithms&lt;/h3&gt;
&lt;p&gt;Today, Deep learning is showing better performance because of availability of big data. But, training on huge data makes learning process much slower. So, In order to speed up  efficiency of learning models we use fast optimization algorithms like mini-batch gradient descent, stochastic gradient descent, Adagrad, momentum, RMSprop, and Adam.&lt;/p&gt;

&lt;h4 id=&quot;mini-batch-gradient-descent&quot;&gt;Mini-batch gradient descent&lt;/h4&gt;
&lt;p&gt;Suppose we have &lt;code class=&quot;highlighter-rouge&quot;&gt;m = 50 million&lt;/code&gt;, to train this data it will take a huge processing time for one step. And also, 50 million won‚Äôt fit in the memory at once, so we need other processing to make such a thing.&lt;/p&gt;

&lt;p&gt;In &lt;code class=&quot;highlighter-rouge&quot;&gt;Batch&lt;/code&gt; gradient descent we run the gradient descent on the whole dataset. whereas, in &lt;code class=&quot;highlighter-rouge&quot;&gt;Mini-Batch&lt;/code&gt; gradient descent we run the gradient descent on the mini datasets.&lt;/p&gt;

&lt;p&gt;Some confusing terms:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Batch Size: Total number of training examples present in a single batch i.e. entire datasets&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mini-batch: Small portion of training example taken from whole dataset. for example: 5 subset of 1 universal set.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;EPOCH : One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Iterations is the number of batches needed to complete one epoch.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/mini-batch.png&quot; alt=&quot;mini-batch&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Suppose we have split 5,000,000 training set to&lt;/span&gt;
mini batches of size 1000.
    X&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0 ... 1000
    X&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 1001 ... 2000
    ...
    X&lt;span class=&quot;o&quot;&gt;{}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; ...
&lt;span class=&quot;c&quot;&gt;# here, X{1} is  1st mini-batch with 1000 training examples&lt;/span&gt;
with its corresponding Y&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;      
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h5 id=&quot;understanding-mini-batch-gradient-descent&quot;&gt;Understanding mini-batch gradient descent&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;In mini-batch algorithm, the cost won‚Äôt go down with each step as it does in batch algorithm. It could contain some ups and downs but generally it has to go down (unlike the batch gradient descent where cost function descreases on each&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cost function in Batch vs Mini-batch gradient descent&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/batch-minibatch.png&quot; alt=&quot;mini-batch&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Mini-batch size:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;mini-batch size &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&amp;gt; Batch gradient descent
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;mini-batch size &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&amp;gt; Stochastic gradient descent &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;SGD&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;mini-batch size &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; between 1 and m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&amp;gt; Mini-batch gradient descent
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Batch gradient descent:
    &lt;ul&gt;
      &lt;li&gt;too long per iteration (epoch)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Stochastic gradient descent:
    &lt;ul&gt;
      &lt;li&gt;too noisy regarding cost minimization (can be reduced by using smaller learning rate)&lt;/li&gt;
      &lt;li&gt;won‚Äôt ever converge (reach the minimum cost)
lose speedup from vectorization&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Mini-batch gradient descent:
    &lt;ul&gt;
      &lt;li&gt;faster learning:
        &lt;ul&gt;
          &lt;li&gt;you have the vectorization advantage&lt;/li&gt;
          &lt;li&gt;make progress without waiting to process the entire training set&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;doesn‚Äôt always exactly converge (oscelates in a very small region, but you can reduce learning rate)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Guidelines for choosing mini-batch size:
    &lt;ul&gt;
      &lt;li&gt;If small training set (&amp;lt; 2000 examples) - use batch gradient descent.&lt;/li&gt;
      &lt;li&gt;It has to be a power of 2 (because of the way computer memory is layed out and accessed, sometimes your code runs faster if your mini-batch size is a power of 2): 64, 128, 256, 512, 1024, ‚Ä¶&lt;/li&gt;
      &lt;li&gt;Make sure that mini-batch fits in CPU/GPU memory.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Mini-batch&lt;/code&gt; size is a &lt;code class=&quot;highlighter-rouge&quot;&gt;hyperparameter&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;exponentially-weighted-averages&quot;&gt;Exponentially Weighted averages&lt;/h4&gt;

&lt;p&gt;There are few optimization algorithm which are faster than gradient descent, they are all based on &lt;code class=&quot;highlighter-rouge&quot;&gt;exponentially Weighted averages&lt;/code&gt; or exponentially weighted moving averages (in statistics).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If we have data like the temperature of day through the year it could be like this:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;t&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 40
t&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 49
t&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;3&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 45
...
t&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;180&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 60
...

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;This data is small in winter and big in summer. If we plot this data we will find it some noisy.
Now lets compute the Exponentially weighted averages:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;V0 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0
V1 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.9 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; V0 + 0.1 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; t&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 4		&lt;span class=&quot;c&quot;&gt;# 0.9 and 0.1 are hyperparameters&lt;/span&gt;
V2 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.9 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; V1 + 0.1 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; t&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 8.5
V3 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.9 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; V2 + 0.1 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; t&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;3&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 12.15
...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;General equation
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;V&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;t&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; beta &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; v&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;t-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; + &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1-beta&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; theta&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;t&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;If we plot this it will represent averages over ~ (1 / (1 - beta)) entries:
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;beta &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.9 will average last 10 entries
beta &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.98 will average last 50 entries
beta &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.5 will average last 2 entries
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/weighted-average.png&quot; alt=&quot;mini-batch&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Best beta average for our case is between 0.9 and 0.98&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;understanding-weighted-averages&quot;&gt;Understanding Weighted averages&lt;/h5&gt;
&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/weighted-intuition.png&quot; alt=&quot;mini-batch&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;We can implement this algorithm with more accurate results using a moving window. But the code is more efficient and faster using the exponentially weighted averages algorithm.
Algorithm is very simple:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;v &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0
Repeat
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	Get theta&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;t&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	v &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; beta &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; v + &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1-beta&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; theta&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;t&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h5 id=&quot;bias-correction-in-exponentially-weighted-averages&quot;&gt;Bias correction in exponentially weighted averages&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;The bias correction helps make the exponentially weighted averages more accurate.&lt;/li&gt;
  &lt;li&gt;Because v(0) = 0, the bias of the weighted averages is shifted and the accuracy suffers at the start.&lt;/li&gt;
  &lt;li&gt;To solve the bias issue we have to use this equation:
&lt;code class=&quot;highlighter-rouge&quot;&gt;v(t) = (beta * v(t-1) + (1-beta) * theta(t)) / (1 - beta^t)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;As t becomes larger the &lt;code class=&quot;highlighter-rouge&quot;&gt;(1 - beta^t)&lt;/code&gt; becomes close to 1&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;gradient-descent-with-momentum&quot;&gt;Gradient Descent with momentum&lt;/h4&gt;
&lt;p&gt;Gradient decent with momentum always work faster than gradient descent. &lt;code class=&quot;highlighter-rouge&quot;&gt;The basic idea is: to compute an exponentially weighted average of your gradients, and then use that gradient to update your weights instead&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Our aim is to speed up learning in horizontal direction and slow down  learning in vertical direction.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We want to move learning rate aggressively toward red dot with less oscillations. So implementing Gradient descent with momentum helps in this process.&lt;/p&gt;

&lt;figure&gt;
 &lt;div style=&quot;text-align:center&quot;&gt;
   &lt;img src=&quot;/assets/img/practical-aspect/lr-momentum.png&quot; alt=&quot;mini-batch&quot; /&gt;
 &lt;/div&gt;
&lt;/figure&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# calculate the exponentially weighted averages for your gradients&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# and then update your weights with the new values.&lt;/span&gt;
vdW &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0, vdb &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0
on iteration t:
	&lt;span class=&quot;c&quot;&gt;# can be mini-batch or batch gradient descent&lt;/span&gt;
	compute dw, db on current mini-batch                

	vdW &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; beta &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; vdW + &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1 - beta&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; dW
	vdb &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; beta &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; vdb + &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1 - beta&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; db
	W &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; W - learning_rate &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; vdW
	b &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; b - learning_rate &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; vdb
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;beta&lt;/code&gt; is another &lt;code class=&quot;highlighter-rouge&quot;&gt;hyperparameter&lt;/code&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;beta = 0.9&lt;/code&gt; is very common and works very well in most cases&lt;/li&gt;
  &lt;li&gt;In practice people don‚Äôt bother implementing &lt;code class=&quot;highlighter-rouge&quot;&gt;bias correction&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;rmsprop&quot;&gt;RMSprop&lt;/h4&gt;

&lt;p&gt;Root mean square prop. (RMSprop) is an algorithm speeds up the gradient descent. RMSprop will make the cost function move slower on the vertical direction and faster on the horizontal direction in the following example:&lt;/p&gt;

&lt;figure&gt;
 &lt;div style=&quot;text-align:center&quot;&gt;
   &lt;img src=&quot;/assets/img/practical-aspect/RMSprop.png&quot; alt=&quot;mini-batch&quot; /&gt;
 &lt;/div&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Note:&lt;/code&gt; Ensure that sdW is not zero by adding a small value epsilon (e.g. epsilon = 10&lt;sup&gt;-8&lt;/sup&gt;) to it:
&lt;code class=&quot;highlighter-rouge&quot;&gt;W = W - learning_rate * dW / (sqrt(sdW) + epsilon)&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;adam-optimization-algorithm&quot;&gt;Adam optimization algorithm&lt;/h4&gt;
&lt;p&gt;RMSprop and Adam optimization algorithms are some algorithm which have shown to work well across a wide range of deep learning architectures. Adam optimization simply puts RMSprop and momentum together. Adam stands for &lt;strong&gt;Adaptive Moment Estimation&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Implementation of Adam&lt;/p&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;cp&quot;&gt;# can be mini-batch or batch gradient descent
&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;                

	&lt;span class=&quot;n&quot;&gt;vdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vdW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;     &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;vdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;     &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;sdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sdW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;   &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RMSprop&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;sdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;   &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RMSprop&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;vdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fixing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;vdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fixing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;sdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fixing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;sdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fixing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sdW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Hyperparameters for Adam:
    &lt;ul&gt;
      &lt;li&gt;Learning rate: needed to be tuned.&lt;/li&gt;
      &lt;li&gt;beta1: parameter of the momentum - &lt;code class=&quot;highlighter-rouge&quot;&gt;0.9&lt;/code&gt; is recommended by default.&lt;/li&gt;
      &lt;li&gt;beta2: parameter of the RMSprop - &lt;code class=&quot;highlighter-rouge&quot;&gt;0.999&lt;/code&gt; is recommended by default.&lt;/li&gt;
      &lt;li&gt;epsilon: 10&lt;sup&gt;-8&lt;/sup&gt; is recommended by default.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;learning-rate-decay&quot;&gt;Learning rate decay&lt;/h4&gt;
&lt;p&gt;we can speed up learning algorithm by slowly reducing the learning rate over time aka &lt;code class=&quot;highlighter-rouge&quot;&gt;learning rate decay&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For mini-batch gradient decent, if learning rate (alpha) is fixed, then it won‚Äôt converge i.e. don‚Äôt reach the optimum point instead it will meander around  globlal minima. Like above figure. But by making the learning rate decay (decrease) with iterations it will be much closer to it because the steps (and possible oscillations) near the optimum are smaller.&lt;/p&gt;

&lt;p&gt;As mentioned before mini-batch gradient descent won‚Äôt reach the optimum point (converge). But by making the learning rate decay with iterations it will be much closer to it because the steps (and possible oscillations) near the optimum are smaller.&lt;/p&gt;

&lt;p&gt;One technique equations is &lt;code class=&quot;highlighter-rouge&quot;&gt;learning_rate = (1 / (1 + decay_rate * epoch_num)) * learning_rate_zero&lt;/code&gt;&lt;/p&gt;

&lt;figure&gt;
  &lt;div style=&quot;text-align:center&quot;&gt;
    &lt;img src=&quot;/assets/img/practical-aspect/lr-decay.png&quot; alt=&quot;lr-decay&quot; /&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;We can divide the dataset of 2000 examples into batches of 500 then it will take 4 iterations to complete 1 epoch.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Some people perform learning rate decay discretely - repeatedly decrease after some number of epochs.&lt;/li&gt;
  &lt;li&gt;Some people are making changes to the learning rate manually.&lt;/li&gt;
  &lt;li&gt;Other Learning rate decay methods
    &lt;ul&gt;
      &lt;li&gt;exponential decay:  &lt;strong&gt;learning_rate = 0.95&lt;sup&gt;epoch_num&lt;/sup&gt; * learning_rate_zero&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;learning_rate = k/sqrt(epoch_num) * learning_rate_zero&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;decrete staircase method&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;decay_rate&lt;/code&gt; is another &lt;code class=&quot;highlighter-rouge&quot;&gt;hyperparameter&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;the-problem-of-local-optima&quot;&gt;The problem of local optima&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The normal local optima is not likely to appear in a deep neural network because data is usually high dimensional. For point to be a local optima it has to be a local optima for each of the dimensions which is highly unlikely.&lt;/li&gt;
  &lt;li&gt;It‚Äôs unlikely to get stuck in a bad local optima in high dimensions, it is much more likely to get to the saddle point rather to the local optima, which is not a problem.&lt;/li&gt;
  &lt;li&gt;Plateaus can make learning slow:
    &lt;ul&gt;
      &lt;li&gt;Plateau is a region where the derivative is close to zero for a long time.&lt;/li&gt;
      &lt;li&gt;This is where algorithms like momentum, RMSprop or Adam can help.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hyperparameter-tuning&quot;&gt;Hyperparameter tuning&lt;/h3&gt;

&lt;h4 id=&quot;tuning-process&quot;&gt;Tuning process&lt;/h4&gt;
&lt;h4 id=&quot;using-an-appropriate-scale-to-pick-hyperparameter&quot;&gt;Using an appropriate scale to pick hyperparameter&lt;/h4&gt;
&lt;h4 id=&quot;hyperparameters-tuning-practice-pandas-vs-caviar&quot;&gt;Hyperparameters tuning practice: Pandas vs. Caviar&lt;/h4&gt;

&lt;h3 id=&quot;batch-normalization&quot;&gt;Batch Normalization&lt;/h3&gt;

&lt;h4 id=&quot;normalizing-activations-in-a-network&quot;&gt;Normalizing activations in a network&lt;/h4&gt;
&lt;h4 id=&quot;fitting-batch-norm-into-neural-network&quot;&gt;Fitting Batch Norm into neural network&lt;/h4&gt;
&lt;h4 id=&quot;why-does-batch-norm-work&quot;&gt;Why does Batch Norm Work&lt;/h4&gt;
&lt;h4 id=&quot;batch-norm-at-test-time&quot;&gt;Batch Norm at test time&lt;/h4&gt;

&lt;h3 id=&quot;multiclass-classification&quot;&gt;Multiclass classification&lt;/h3&gt;

&lt;h4 id=&quot;softmax-regression&quot;&gt;Softmax Regression&lt;/h4&gt;
&lt;h4 id=&quot;training-a-softmax-classifier&quot;&gt;Training a Softmax classifier&lt;/h4&gt;

&lt;h3 id=&quot;introduction-to-programming-frameworks&quot;&gt;Introduction to programming Frameworks&lt;/h3&gt;
</description>
        <pubDate>Mon, 16 Apr 2018 00:00:00 +0530</pubDate>
        <link>http://bikash-jaiswal.github.io/2018/04/16/Practical-aspects-of-Deep-Learning.html</link>
        <guid isPermaLink="true">http://bikash-jaiswal.github.io/2018/04/16/Practical-aspects-of-Deep-Learning.html</guid>
        
        <category>Deep-Learning</category>
        
        
        <category>Deep</category>
        
        <category>Learning</category>
        
        <category>Notes</category>
        
      </item>
    
  </channel>
</rss>
