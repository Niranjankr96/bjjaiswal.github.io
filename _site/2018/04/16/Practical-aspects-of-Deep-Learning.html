<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Practical aspects of Deep Learning - Bikash-Jaiswal Blog</title>
    <meta name="author"  content="bikash">
    <meta name="description" content="Practical aspects of Deep Learning">
    <meta name="keywords"  content="Deep-Learning">
    <!-- Open Graph -->
    <meta property="og:title" content="Practical aspects of Deep Learning - Bikash-Jaiswal Blog">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://bikash-jaiswal.github.io/2018/04/16/Practical-aspects-of-Deep-Learning.html">
    <meta property="og:description" content="You have the capacity to learn from your mistakes, and you will learn a lot today.">
    <meta property="og:site_name" content="Bikash-Jaiswal Blog">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"] ],
			displayMath: [ ["$$", "$$"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>

	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/about.html">about</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header class="g-banner post-header post-pattern-circuitBoard bgcolor-default " data-theme="default">
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="tags#Deep-Learning" class="post-tag">Deep-Learning</a>
          
        
      </div>
      <h1>Practical aspects of Deep Learning</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i><a href="http://bikash-jaiswal.github.io" target="_blank" rel="author">bikash</a></></span>
        <time class="post-meta-item" datetime="18-04-16"><i class="iconfont icon-date"></i>16 Apr 2018</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('https://i2.wp.com/philosophyofbrains.com/wp-content/uploads/2016/05/Problem-Mental-Causation-Pic.jpg?resize=1280%2C585') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <p>After implementation of a neural network, we have gained enough vim to better understand the black box of Deep Learning and to learn all the practical aspects of making our neural network work even better. We are going to learn various tricks or technique like:</p>
<ol>
  <li>Hyperparameter tuning</li>
  <li>Setting the datasets</li>
  <li>Optimization algorithm- makes learning algorithm to learn in a reasonable time</li>
</ol>

<h2 id="practical-aspects-of-deep-learning">Practical aspects of Deep Learning</h2>
<p>When we start to solve a new problem in using deep learning, we can never decide earlier what to choose like - what learning rate? how many hidden layers? which activation functions to choose and for which layers? To find the answer we have to follow iterative process of <code class="highlighter-rouge">Idea ---&gt; code ---&gt; Experiment</code>. Even seasoned deep learning expert find it almost impossible to correctly guess the best choice of hyperparameters the very first time.</p>

<h3 id="setting-up-your-machine-learning-application">Setting up your Machine Learning Application</h3>
<h5 id="train--dev--test-sets">1. Train / Dev / Test sets</h5>
<p>Your data will be split into three parts:</p>
<ul>
  <li>Training set. (Has to be the largest set)</li>
  <li>Development or “dev” set.</li>
  <li>Testing set.</li>
</ul>

<figure>
  <div style="text-align:center">
  <img src="/assets/img/ml-strategies/new-dist.png" alt="my alt text" />
      <figcaption> Strategy of distribution in Deep Learning </figcaption>
    </div>
  </figure>

<blockquote>
  <p>Generally, we have give just Training set and Test set in real life and also in Kaggle competitions. To construct the development set use following technique:</p>
  <ul>
    <li>Test set size = 10,000,000, then split like below</li>
    <li>Test set size = index from 1 - 9,900,000 i.e. 98% of original test set</li>
    <li>Development set = index from 9,900,001 - 10,000,000 i.e. 1% of original test sets.</li>
  </ul>
</blockquote>

<p><strong>You will try to build a model upon training set then try to optimize hyperparameters on dev set as much as possible. Then after your model is ready you try and evaluate the testing set.</strong></p>

<p><code class="highlighter-rouge">Make sure the dev and test set are coming from the same distribution</code>. Suppose training pictures is from the web and the dev/test pictures are from users cell phone they will mismatch. It is better to make sure that dev and test set are from the same distribution.</p>

<p>For more knowledge on Train/dev/test set distributions topic follow <a href="https://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html">Machine Learning Strategy In Deep Learning</a> 3rd course in Deep learning specialization.</p>

<h5 id="bias---variance">2. Bias - Variance</h5>

<p>One of the quick question to evaluate someone’s technical skill on Machine Learning or Deep Learning is to ask him/her about bias/ Variance and Overfitting and Underfitting.</p>

<p><code class="highlighter-rouge">It is simple and vital topic but difficult to master.</code></p>

<p>More information on the problem of overfitting and underfitting can be found on <a href="https://github.com/bikash-jaiswal/Machine-Learning-Notes/blob/master/3.a.The-problem-of-overfitting.md">The problem of Underfitting</a> course for Machine learning taught by Andrew Ng in <a href="https://www.coursera.org/learn/machine-learning">coursera</a>.</p>

<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/bias-variance.png" alt="Bias-variance" />
    <figcaption> Bias-Variance </figcaption>
  </div>
</figure>

<p><strong>Overfitting</strong> : models with overfitting problem has good performance on the training data, poor generliazation to other data. It is usually caused by a complicated function that creates a lot of unnecessary curves and angles unrelated to the data.</p>

<p><strong>Underfitting</strong>: models that can neither model the training data nor generalize to new data. It is usually caused by a function that is too simple or uses too few features.</p>

<p>Analysis Bias and Variance with training error rate and validation error value. Assumption made for below comparison: human error = 0%</p>
<ul>
  <li>High variance (overfitting):
    <ul>
      <li>Training error: 1%</li>
      <li>Dev error: 11%</li>
    </ul>
  </li>
  <li>High Bias (underfitting):
    <ul>
      <li>Training error: 15%</li>
      <li>Dev error: 14%</li>
    </ul>
  </li>
  <li>High Bias (underfitting) &amp;&amp; High variance (overfitting) :
    <ul>
      <li>Training error: 15%</li>
      <li>Test error: 30%</li>
    </ul>
  </li>
  <li>Best:
    <ul>
      <li>Training error: 0.5%</li>
      <li>Test error: 1%</li>
    </ul>
  </li>
</ul>

<p>To know more about human level performance see <a href="https://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html">Machine Learning Strategy In Deep Learning</a> 3rd course in Deep learning specialization.</p>

<h5 id="basic-recipe-for-machine-learning">3. Basic Recipe for Machine Learning</h5>
<ul>
  <li>If your algorithm has a high bias:
    <ul>
      <li>Try to make your NN bigger (size of hidden units, number of layers)</li>
      <li>Try a different model that is suitable for your data.
Try to run it longer.
Different (advanced) optimization algorithms.</li>
    </ul>
  </li>
  <li>If your algorithm has a high variance:
    <ul>
      <li>More data.</li>
      <li>Try regularization.</li>
      <li>Try a different model that is suitable for your data.</li>
    </ul>
  </li>
  <li>
    <p>You should try the previous two points until you have a low bias and low variance.</p>
  </li>
  <li>
    <p>In the older days before deep learning, there was a “Bias/variance trade-off”. But because now you have more options/tools for solving the bias and variance problem its really helpful to use deep learning.</p>
  </li>
  <li>Training a bigger neural network never hurts.</li>
</ul>

<h3 id="regularizing-your-neural-network">Regularizing your neural network</h3>
<p>As of solution listed in case of high variance, getting more data is not always feasible in every case of application, nevertheless, trying regularization is always possible.</p>

<h5 id="applying-regularization-in-logistic-regression">Applying regularization in logistic regression</h5>
<p>Here, <code class="highlighter-rouge">||W|| = sum of absolute values of all weight</code> and the cost function of logistic regression is <code class="highlighter-rouge">J(w,b) = (1/m) * Sum(L(y(i),y'(i)))</code> and <code class="highlighter-rouge">lambda</code> is  regularization parameter (another hyperparameter).</p>
<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/regularization-LR.png" alt="regularization in Logistic regression" />
    <figcaption> Regularization in Logistic Regression </figcaption>
  </div>
</figure>

<p>Though <code class="highlighter-rouge">L2 regularization is used much</code> despite <code class="highlighter-rouge">L1 regularization</code>, people thinks, can help with compressing the model as it makes <code class="highlighter-rouge">W</code> sparse by setting some of W’s value zero and also uses less memory to store the model.</p>

<h5 id="regularization-in-neural-network">Regularization in Neural Network.</h5>

<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/regu-nn.png" alt="regularization in Neural network" />
    <figcaption> Regularization in Neural Network </figcaption>
  </div>
</figure>

<ul>
  <li>Update the gradient of <code class="highlighter-rouge">W</code> by:
    <ul>
      <li><code class="highlighter-rouge">dW[l] = (from backpropagation) +  lambda/m * W[l] </code></li>
      <li><code class="highlighter-rouge">W[l] = W[l] -lr*dW[l]</code></li>
    </ul>
  </li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>w[l] = w[l] - lr * dw[l]
     = w[l] - lr * ((from back propagation) + lambda/m * w[l])
     = w[l] - (lr*lambda/m) * w[l] - lr * (from back propagation)
     = (1 - (lr*lambda)/m) * w[l] - lr * (from back propagation)
</code></pre>
</div>
<ul>
  <li>
    <p>The new term <code class="highlighter-rouge">(1 - (learning_rate*lambda)/m) * w[l]</code> causes the weight to decay in proportion to its size.</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">(lambda/2m) * Sum((||W[l]||^2)</code>  penalizes the weight matrices from being too large.</p>
  </li>
</ul>

<h5 id="how-does-regularization-prevent-overfitting">How does regularization prevent overfitting</h5>
<p>Some Intuition that can help us in finding why and how does regularization help with overfitting and reducing variance problems?</p>

<p><code class="highlighter-rouge">Intuition I</code>: If regularization parameter <code class="highlighter-rouge">lambda</code> is too big.</p>
<ul>
  <li>a lot of w’s will be close to zeros which will make the Neural network simpler (you can think of it as it would behave closer to logistic regression with more hidden layers).</li>
</ul>
<figure>
    <div style="text-align:center">
      <img src="/assets/img/practical-aspect/simpler-nn.png" alt="simpler-nn" />
      <figcaption> NN when lambda is too large </figcaption>
    </div>
  </figure>
<ul>
  <li>If lambda is good enough: It will just reduce some weights that makes the neural network overfit.</li>
</ul>

<p><code class="highlighter-rouge">Intuition II with tanh function</code>:</p>
<ul>
  <li>If lambda is too large, w’s will be small (close to zero) - will use the linear part of the tanh activation function, so we will go from non linear activation to roughly linear which would make the NN a roughly linear classifier.</li>
  <li>If lambda good enough it will just make some of tanh activations roughly linear which will prevent overfitting.</li>
  <li>If lambda is good enough: It will just reduce some weights that makes the neural network overfit.</li>
</ul>

<p><strong><code class="highlighter-rouge">Implementation tip</code></strong>: If you implement gradient descent, one of the steps to debug gradient descent is to plot the cost function (J) as a function of the number of iterations of gradient descent and you want to see that the cost function J <strong>decreases monotonically</strong> after every elevation of gradient descent with regularization. If you plot the old definition of J (no regularization) then you might not see it decrease monotonically.
monotonically decreassing</p>
<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/monotonically decreassing.png" alt="monotonically decreassing" />
    <figcaption>monotonically decreassing
 </figcaption>
  </div>
</figure>

<h3 id="setting-up-your-optimization-problem">Setting up your optimization problem</h3>

<h3 id="different-optimization-algorithms">Different Optimization algorithms</h3>

<h3 id="hyperparameter-tuning">Hyperparameter tuning</h3>

<h3 id="batch-normalization">Batch Normalization</h3>

<h3 id="multiclass-classification">Multiclass classification</h3>

    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="/assets/img/profile.png" alt="">
      </div>
      <div class="author-name" rel="author">bikash</div>
      <div class="bio">
        <p></p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="https://www.linkedin.com/in/bikashjaiswal" target="_blank">
                    <i class="iconfont icon-linkedin"></i>
                </a>
        </li>
        
        <li>
          <a href="https://www.github.com/bikash-jaiswal" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
        <li>
          <a href="bjjaiswal@gmail.com" target="_blank">
                    <i class="iconfont icon-email"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html" class="read-next-link"></a>
        <section>
          <span>How to Structure Machine Learning Projects</span>
          <p>Even after developing a model, We find that prediction ac...</p>
        </section>
        
        <div class="filter"></div>
        <img src="https://i2.wp.com/philosophyofbrains.com/wp-content/uploads/2016/05/Problem-Mental-Causation-Pic.jpg?resize=1280%2C585" alt="">
        
     </div>
      

      
    </section>
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
    </section>
  </section>

  <footer class="g-footer">
  <section>Bikash-Jaiswal Blog ©
  
  
    2017
    -
  
  2018
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a> | <a href="https://github.com/kaeyleo/jekyll-theme-H2O">Theme H2O</a></section>
</footer>



  
  <script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document,
        s = d.createElement('script');
      s.src = 'https://bikash-jaiswal.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());

      (d.head || d.body).appendChild(s);
    })();
  </script>
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
