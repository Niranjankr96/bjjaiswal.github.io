<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Practical aspects of Deep Learning - Bikash-Jaiswal Blog</title>
    <meta name="author"  content="bikash">
    <meta name="description" content="Practical aspects of Deep Learning">
    <meta name="keywords"  content="Deep-Learning">
    <!-- Open Graph -->
    <meta property="og:title" content="Practical aspects of Deep Learning - Bikash-Jaiswal Blog">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://bikash-jaiswal.github.io/2018/04/16/Practical-aspects-of-Deep-Learning.html">
    <meta property="og:description" content="You have the capacity to learn from your mistakes, and you will learn a lot today.">
    <meta property="og:site_name" content="Bikash-Jaiswal Blog">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"] ],
			displayMath: [ ["$$", "$$"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>

	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
</head>


<body>
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/about.html">about</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header class="g-banner post-header post-pattern-circuitBoard bgcolor-default " data-theme="default">
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="tags#Deep-Learning" class="post-tag">Deep-Learning</a>
          
        
      </div>
      <h1>Practical aspects of Deep Learning</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i><a href="http://bikash-jaiswal.github.io" target="_blank" rel="author">bikash</a></></span>
        <time class="post-meta-item" datetime="18-04-16"><i class="iconfont icon-date"></i>16 Apr 2018</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('http://www.di.univr.it/documenti/Seminario/immagine/immagine240319.jpg') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <p>After implementation of a neural network, we have gained enough vim to better understand the black box of Deep Learning and to learn all the practical aspects of making our neural network work even better. We are going to learn various tricks or technique like:</p>
<ol>
  <li>Hyperparameter tuning</li>
  <li>Setting the datasets</li>
  <li>Optimization algorithm- makes learning algorithm to learn in a reasonable time</li>
</ol>

<h2 id="practical-aspects-of-deep-learning">Practical aspects of Deep Learning</h2>
<p>When we start to solve a new problem in using deep learning, we can never decide earlier what to choose like - what learning rate? how many hidden layers? which activation functions to choose and for which layers? To find the answer we have to follow iterative process of <code class="highlighter-rouge">Idea ---&gt; code ---&gt; Experiment</code>. Even seasoned deep learning expert find it almost impossible to correctly guess the best choice of hyperparameters the very first time.</p>

<h3 id="setting-up-your-machine-learning-application">Setting up your Machine Learning Application</h3>
<h5 id="train--dev--test-sets">1. Train / Dev / Test sets</h5>
<p>Your data will be split into three parts:</p>
<ul>
  <li>Training set. (Has to be the largest set)</li>
  <li>Development or “dev” set.</li>
  <li>Testing set.</li>
</ul>

<figure>
  <div style="text-align:center">
  <img src="/assets/img/ml-strategies/new-dist.png" alt="my alt text" />
      <figcaption> Strategy of distribution in Deep Learning </figcaption>
    </div>
  </figure>

<blockquote>
  <p>Generally, we have give just Training set and Test set in real life and also in Kaggle competitions. To construct the development set use following technique:</p>
  <ul>
    <li>Test set size = 10,000,000, then split like below</li>
    <li>Test set size = index from 1 - 9,900,000 i.e. 98% of original test set</li>
    <li>Development set = index from 9,900,001 - 10,000,000 i.e. 1% of original test sets.</li>
  </ul>
</blockquote>

<p><strong>You will try to build a model upon training set then try to optimize hyperparameters on dev set as much as possible. Then after your model is ready you try and evaluate the testing set.</strong></p>

<p><code class="highlighter-rouge">Make sure the dev and test set are coming from the same distribution</code>. Suppose training pictures is from the web and the dev/test pictures are from users cell phone they will mismatch. It is better to make sure that dev and test set are from the same distribution.</p>

<p>For more knowledge on Train/dev/test set distributions topic follow <a href="https://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html">Machine Learning Strategy In Deep Learning</a> 3rd course in Deep learning specialization.</p>

<h5 id="bias---variance">2. Bias - Variance</h5>

<p>One of the quick question to evaluate someone’s technical skill on Machine Learning or Deep Learning is to ask him/her about bias/ Variance and Overfitting and Underfitting.</p>

<p><code class="highlighter-rouge">It is simple and vital topic but difficult to master.</code></p>

<p>More information on the problem of overfitting and underfitting can be found on <a href="https://github.com/bikash-jaiswal/Machine-Learning-Notes/blob/master/3.a.The-problem-of-overfitting.md">The problem of Underfitting</a> course for Machine learning taught by Andrew Ng in <a href="https://www.coursera.org/learn/machine-learning">coursera</a>.</p>

<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/bias-variance.png" alt="Bias-variance" />
    <figcaption> Bias-Variance </figcaption>
  </div>
</figure>

<p><strong>Overfitting</strong> : models with overfitting problem has good performance on the training data, poor generliazation to other data. It is usually caused by a complicated function that creates a lot of unnecessary curves and angles unrelated to the data.</p>

<p><strong>Underfitting</strong>: models that can neither model the training data nor generalize to new data. It is usually caused by a function that is too simple or uses too few features.</p>

<p>Analysis Bias and Variance with training error rate and validation error value. Assumption made for below comparison: human error = 0%</p>
<ul>
  <li>High variance (overfitting):
    <ul>
      <li>Training error: 1%</li>
      <li>Dev error: 11%</li>
    </ul>
  </li>
  <li>High Bias (underfitting):
    <ul>
      <li>Training error: 15%</li>
      <li>Dev error: 14%</li>
    </ul>
  </li>
  <li>High Bias (underfitting) &amp;&amp; High variance (overfitting) :
    <ul>
      <li>Training error: 15%</li>
      <li>Test error: 30%</li>
    </ul>
  </li>
  <li>Best:
    <ul>
      <li>Training error: 0.5%</li>
      <li>Test error: 1%</li>
    </ul>
  </li>
</ul>

<p>To know more about human level performance see <a href="https://bikash-jaiswal.github.io/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html">Machine Learning Strategy In Deep Learning</a> 3rd course in Deep learning specialization.</p>

<h5 id="basic-recipe-for-machine-learning">3. Basic Recipe for Machine Learning</h5>
<ul>
  <li>If your algorithm has a high bias:
    <ul>
      <li>Try to make your NN bigger (size of hidden units, number of layers)</li>
      <li>Try a different model that is suitable for your data.
Try to run it longer.
Different (advanced) optimization algorithms.</li>
    </ul>
  </li>
  <li>If your algorithm has a high variance:
    <ul>
      <li>More data.</li>
      <li>Try regularization.</li>
      <li>Try a different model that is suitable for your data.</li>
    </ul>
  </li>
  <li>
    <p>You should try the previous two points until you have a low bias and low variance.</p>
  </li>
  <li>
    <p>In the older days before deep learning, there was a “Bias/variance trade-off”. But because now you have more options/tools for solving the bias and variance problem its really helpful to use deep learning.</p>
  </li>
  <li>Training a bigger neural network never hurts.</li>
</ul>

<h3 id="regularizing-your-neural-network">Regularizing your neural network</h3>
<p>As of solution listed in case of high variance, getting more data is not always feasible in every case of application, nevertheless, trying regularization is always possible.</p>

<h5 id="applying-regularization-in-logistic-regression">Applying regularization in logistic regression</h5>
<p>Here, <code class="highlighter-rouge">||W|| = sum of absolute values of all weight</code> and the cost function of logistic regression is <code class="highlighter-rouge">J(w,b) = (1/m) * Sum(L(y(i),y'(i)))</code> and <code class="highlighter-rouge">lambda</code> is  regularization parameter (another hyperparameter).</p>
<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/regularization-LR.png" alt="regularization in Logistic regression" />
    <figcaption> Regularization in Logistic Regression </figcaption>
  </div>
</figure>

<p>Though <code class="highlighter-rouge">L2 regularization is used much</code> despite <code class="highlighter-rouge">L1 regularization</code>, people thinks, can help with compressing the model as it makes <code class="highlighter-rouge">W</code> sparse by setting some of W’s value zero and also uses less memory to store the model.</p>

<h5 id="regularization-in-neural-network">Regularization in Neural Network.</h5>

<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/regu-nn.png" alt="regularization in Neural network" />
    <figcaption> Regularization in Neural Network </figcaption>
  </div>
</figure>

<ul>
  <li>Update the gradient of <code class="highlighter-rouge">W</code> by:
    <ul>
      <li><code class="highlighter-rouge">dW[l] = (from backpropagation) +  lambda/m * W[l] </code></li>
      <li><code class="highlighter-rouge">W[l] = W[l] -lr*dW[l]</code></li>
    </ul>
  </li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>
w[l] = w[l] - lr * dw[l]
     = w[l] - lr * ((from back propagation) + lambda/m * w[l])
     = w[l] - (lr*lambda/m) * w[l] - lr * (from back propagation)
     = (1 - (lr*lambda)/m) * w[l] - lr * (from back propagation)

</code></pre>
</div>
<ul>
  <li>
    <p>The new term <code class="highlighter-rouge">(1 - (learning_rate*lambda)/m) * w[l]</code> causes the weight to decay in proportion to its size.</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">(lambda/2m) * Sum((||W[l]||^2)</code>  penalizes the weight matrices from being too large.</p>
  </li>
</ul>

<h5 id="how-does-regularization-prevent-overfitting">How does regularization prevent overfitting</h5>
<p>Some Intuition that can help us in finding why and how does regularization help with overfitting and reducing variance problems?</p>

<p><code class="highlighter-rouge">Intuition I</code>: If regularization parameter <code class="highlighter-rouge">lambda</code> is too big.</p>
<ul>
  <li>a lot of w’s will be close to zeros which will make the Neural network simpler (you can think of it as it would behave closer to logistic regression with more hidden layers).</li>
</ul>
<figure>
    <div style="text-align:center">
      <img src="/assets/img/practical-aspect/simpler-nn.png" alt="simpler-nn" />
      <figcaption> NN when lambda is too large </figcaption>
    </div>
  </figure>
<ul>
  <li>If lambda is good enough: It will just reduce some weights that makes the neural network overfit.</li>
</ul>

<p><code class="highlighter-rouge">Intuition II with tanh function</code>:</p>
<ul>
  <li>If lambda is too large, w’s will be small (close to zero) - will use the linear part of the tanh activation function, so we will go from non linear activation to roughly linear which would make the NN a roughly linear classifier.</li>
  <li>If lambda good enough it will just make some of tanh activations roughly linear which will prevent overfitting.</li>
</ul>

<p><strong><code class="highlighter-rouge">Implementation tip</code></strong>: If you implement gradient descent, one of the steps to debug gradient descent is to plot the cost function (J) as a function of the number of iterations of gradient descent and you want to see that the cost function J <strong>decreases monotonically</strong> after every elevation of gradient descent with regularization. If you plot the old definition of J (no regularization) then you might not see it decrease monotonically.
monotonically decreassing</p>
<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/monotonically decreassing.png" alt="monotonically decreassing" />
    <figcaption>monotonically decreassing
 </figcaption>
  </div>
</figure>

<h5 id="dropout-technique">Dropout technique</h5>
<p>Dropout	is	a	technique	used	to	improve	over-fit	on	neural	networks,	we	should	use	Dropout	along with	other	techniques	like	L2	Regularization.</p>
<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/dropout.png" alt="Dropout" />
    <figcaption>Dropout
 </figcaption>
  </div>
</figure>

<p><code class="highlighter-rouge">Dropout Intuition:</code> Go through each of the layers of the network and set some probability for eliminating a node in neural network.  So, we end up with a much smaller, really much diminished network.</p>

<ul>
  <li>Implementation of Dropout aka Inverted dropout</li>
</ul>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">keep_prob</span> <span class="o">=</span> <span class="mf">0.8</span>   <span class="c"># 0 &lt;= keep_prob &lt;=1</span>
<span class="c"># the generated number that are less than 0.8 will be dropped.</span>
<span class="c">#80% stay, 20% dropped</span>
<span class="n">l</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c"># this code is only for layer 3</span>

<span class="n">d3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">a</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">keep_prob</span>

<span class="n">a3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">a3</span><span class="p">,</span><span class="n">d3</span><span class="p">)</span>   <span class="c"># keep only the values in d3</span>

<span class="c"># increase a3 to not reduce the expected value of output</span>
<span class="c"># (ensures that the expected value of a3 remains the same)</span>
<span class="c"># to solve the scaling problem</span>
<span class="n">a3</span> <span class="o">=</span> <span class="n">a3</span> <span class="o">/</span> <span class="n">keep_prob</span>      
</code></pre>
</div>
<ul>
  <li>
    <p>If there are 50 neuron than 10 neurons will be shut off</p>
  </li>
  <li>
    <p>Vector d[l] is used for forward and back propagation and is the same for them, but it is different for each iteration (pass) or training example.</p>
  </li>
  <li>
    <p>At test time we don’t use dropout. If you implement dropout at test time - it would add noise to predictions.</p>
  </li>
</ul>

<h5 id="understanding-dropout">Understanding Dropout</h5>
<p><code class="highlighter-rouge">Intuition:</code> Dropout randomly knocks out units in your network. So it’s as if on every iteration you’re working with a smaller NN, and so using a smaller NN seems like it should have a regularizing effect.</p>

<p><code class="highlighter-rouge">Another Intution:</code> can’t rely on any one feature, so have to spread out weights.</p>

<ul>
  <li>It’s possible to show that dropout has a similar effect to L2 regularization.</li>
  <li>Dropout can have different keep_prob per layer.</li>
  <li>The input layer dropout has to be near 1 (or 1 - no dropout) because you don’t want to eliminate a lot of features.</li>
  <li>If you’re more worried about some layers overfitting than others, you can set a lower keep_prob for some layers than others. The downside is, this gives you even more hyperparameters to search for using cross-validation. One other alternative might be to have some layers where you apply dropout and some layers where you don’t apply dropout and then just have one hyperparameter, which is a keep_prob for the layers for which you do apply dropouts.</li>
  <li>A lot of researchers are using dropout with Computer Vision (CV) because they have a very big input size and almost never have enough data, so overfitting is the usual problem. And dropout is a regularization technique to prevent overfitting.</li>
  <li>
    <p>A downside of dropout is that the cost function J is not well defined and it will be hard to debug (plot J by iteration).</p>
  </li>
  <li>To solve that you’ll need to turn off dropout, set all the <code class="highlighter-rouge">keep_probs</code> to 1, and then run the code and check that it monotonically decreases J and then turn on the dropouts again.</li>
</ul>

<h5 id="wheretousedropoutlayers">Where	to	use	Dropout	layers</h5>
<p>Normally	some	deep	learning	models use Dropout on	the	fully	connected	layers,	but	is	also	possible to	use	dropout	after	the	max-pooling	layers,	creating	some	kind	of	image	noise	augmentation.</p>

<h5 id="other-regularization-methods">Other regularization methods</h5>
<ul>
  <li>Data augmentation:
    <ul>
      <li>For example in a computer vision data:
        <ul>
          <li>You can flip all your pictures horizontally this will give you m more data instances.</li>
          <li>You could also apply a random position and rotation to an image to get more data.</li>
        </ul>
      </li>
      <li>For example in OCR, you can impose random rotations and distortions to digits/letters.</li>
      <li>New data obtained using this technique isn’t as good as the real independent data, but still can be used as a regularization technique.</li>
    </ul>
    <figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/data-augment.png" alt="data augmentation" />
    <figcaption>Data Augmentation
 </figcaption>
  </div>
</figure>
  </li>
  <li>Early stopping:
    <ul>
      <li>In this technique we plot the training set and the dev set cost together for each iteration. At some iteration the dev set cost will stop decreasing and will start increasing.</li>
      <li>We will pick the point at which the training set error and dev set error are best (lowest training cost with lowest dev cost).</li>
      <li>We will take these parameters as the best parameters.</li>
    </ul>
    <figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/early-stopping.png" alt="Early stopping" />
    <figcaption>Early stopping
 </figcaption>
  </div>
</figure>
    <ul>
      <li><code class="highlighter-rouge">Advantages:</code> you don’t need to search a hyperparameter like in other regularization approaches (like lambda in L2 regularization).</li>
      <li><code class="highlighter-rouge">Disadvantages:</code> Early stopping simultaneously tries to minimize the cost function and not to overfit which contradicts the orthogonalization approach (will be discussed further). So, use L2 regularization.</li>
    </ul>
  </li>
  <li>Model Ensembles:
    <ul>
      <li>Algorithm:
        <ul>
          <li>Train multiple independent models.</li>
          <li>At test time average their results.</li>
        </ul>
      </li>
      <li>It can get you extra 2% performance.</li>
      <li>It reduces the generalization error.</li>
      <li>You can use some snapshots of your NN at the training ensembles them and take the results.</li>
    </ul>
  </li>
</ul>

<h3 id="setting-up-your-optimization-problem">Setting up your optimization problem</h3>

<h5 id="normalizing-input">Normalizing input</h5>
<p>When training a neural network, one of the techniques that will speed up training is if we have normalized our inputs.</p>

<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/normalizing.png" alt="Early stopping" />
    <figcaption> Normalization of data
 </figcaption>
  </div>
</figure>

<ul>
  <li>Normalization are going on these steps:
    <ul>
      <li>First get the mean of the training set: <code class="highlighter-rouge">mean = (1/m) * sum(x(i))</code></li>
      <li>Then, subtract the mean from each input: <code class="highlighter-rouge">X = X - mean</code> to make your inputs centered around 0.</li>
      <li>Atlast, get the variance of the training set: <code class="highlighter-rouge">variance = (1/m) * sum(x(i)^2)</code>and normalize the variance. <code class="highlighter-rouge">X /= variance</code>.</li>
    </ul>
  </li>
</ul>

<p><code class="highlighter-rouge">Note:</code> These steps should be applied to all training, dev, and testing sets (but using mean and variance of the train set).</p>

<ul>
  <li>Why normalize?
    <ul>
      <li>If we don’t normalize the inputs our cost function will be deep and its shape will be inconsistent (elongated) then optimizing it will take a long time.</li>
      <li>But if we normalize it the opposite will occur. The shape of the cost function will be consistent (look more symmetric like circle in 2D example) and we can use a larger learning rate alpha - the optimization will be faster.</li>
    </ul>
  </li>
</ul>

<h5 id="vanishingexploding-gradients">Vanishing/Exploding gradients</h5>
<blockquote>
  <p>Vanishing and Exploding gradients —-&gt; During training when gradient becomes either too small or too big respectively.</p>
</blockquote>

<p>Consider this 9-layer neural network just after it was initialized.</p>
<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/9-layer.png" alt="vanishing" />
  </div>
</figure>

<p>To understand the problem, suppose that we have a deep neural network with number of layers L, and all the activation functions are linear(identity matrix)  i.e. <code class="highlighter-rouge">g(z)=z</code> and each<code class="highlighter-rouge">b = 0</code>.</p>

<p>Then the output activation is: Y = W<sup>L</sup>W<sup>L-1</sup>W[1]…..W<sup>2</sup>W<sup>1</sup>X where L=10 and W<sup>1</sup>,W<sup>2</sup>,…,W<sup>L-1</sup> are all matrices of size (2,2) because layers [1] to [L-1] have 2 neurons and receive 2 inputs.</p>

<p>Consider the case where every weight is initialized slightly larger than the identity matrix.</p>

<h6 id="exploding-gradients">Exploding Gradients:</h6>
<div class="language-python highlighter-rouge"><pre class="highlight"><code> <span class="n">l</span> <span class="o">=</span> <span class="n">L</span>
<span class="k">if</span> <span class="n">W</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.5</span>   <span class="mi">0</span><span class="p">]</span>
          <span class="p">[</span><span class="mi">0</span>   <span class="mf">1.5</span><span class="p">]</span>
</code></pre>
</div>
<p>This simplifies to y’=W<sup>L</sup>1.5<sup>L−1</sup>X and the values of the activation a<sup>l</sup> increase exponentially with l. When these activations are used in backward propagation, this leads to the exploding gradient problem.</p>

<h6 id="vanishing-gradients">Vanishing gradients</h6>
<p>Similarly, consider the case where every weight is initialized slightly smaller than the identity matrix</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code> <span class="n">l</span> <span class="o">=</span> <span class="n">L</span>
<span class="k">if</span> <span class="n">W</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span>   <span class="mi">0</span><span class="p">]</span>
          <span class="p">[</span><span class="mi">0</span>   <span class="mf">0.5</span><span class="p">]</span>
</code></pre>
</div>
<p>This simplifies to y’=W<sup>L</sup>0.5<sup>L−1</sup>X and the values of the activation a<sup>l</sup> decreases exponentially with l. When these activations are used in backward propagation, this leads to the vanishing gradient problem.</p>

<ul>
  <li>Recently Microsoft trained 152 layers (ResNet)! which is a really big number. With such a deep neural network, if your activations or gradients increase or decrease exponentially as a function of L, then these values could get really big or really small. And this makes training difficult, especially if your gradients are exponentially smaller than L, then gradient descent will take tiny little steps. It will take a long time for gradient descent to learn anything.</li>
</ul>

<h5 id="weight-initialization">Weight initialization</h5>

<ul>
  <li>A partial solution to the Vanishing / Exploding gradients in NN is better or more careful choice of the random initialization of weights</li>
  <li>In a single neuron (Perceptron model): Z = w<sup>1</sup>x<sup>1</sup> + w<sup>2</sup>x<sup>2</sup> + … + w<sup>n</sup>x<sup>n</sup>
    <ul>
      <li>So if <code class="highlighter-rouge">n_x</code> is large we want W’s to be smaller to not explode the cost.</li>
    </ul>
  </li>
  <li>So it turns out that we need the variance which equals <code class="highlighter-rouge">1/n_x</code> to be the range of W’s
So lets say when we initialize W’s like this (better to use with tanh activation):</li>
</ul>

<p>Maintaining the value of the variance of the input and the output of every layer guarantees no exploding/vanishing gradient(<code class="highlighter-rouge">ReLU + Weight Initialization with variance</code>). The recommended initialization is Xavier initialization (or one of its derived methods), for every layer <code class="highlighter-rouge">l</code>:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">n</span><span class="p">[</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</code></pre>
</div>
<p>or variation of this (Bengio et al.):</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">n</span><span class="p">[</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">n</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
</code></pre>
</div>
<p>or Setting initialization part inside sqrt to 2/n[l-1] for ReLU is better</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="p">[</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</code></pre>
</div>
<h5 id="numerical-approximation-in-gradients">Numerical approximation in gradients</h5>
<p>How to make check the implementation of your Back propagation is correct?</p>
<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/numerical.png" alt="vanishing" />
  </div>
</figure>

<p><code class="highlighter-rouge">NOTE:</code> Gradient checking approximates the gradients and is very helpful for finding the errors in your backpropagation implementation but it’s slower than gradient descent (so use only for debugging).</p>

<h5 id="gradient-checking">Gradient checking</h5>
<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/gradient-check.png" alt="vanishing" />
  </div>
</figure>
<ul>
  <li>First take <code class="highlighter-rouge">W[1],b[1],...,W[L],b[L]</code> and reshape into one big vector (theta)</li>
  <li>Then take <code class="highlighter-rouge">dW[1],db[1],...,dW[L],db[L]</code> into one big vector (d_theta</li>
</ul>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">eps</span> <span class="o">=</span> <span class="mi">10</span><span class="o">^-</span><span class="mi">7</span>   <span class="c"># small number</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
 <span class="n">d_theta_approx</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">J</span><span class="p">(</span><span class="n">theta1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">-</span> <span class="n">J</span><span class="p">(</span><span class="n">theta1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">eps</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span><span class="o">*</span><span class="n">eps</span>
</code></pre>
</div>

<ul>
  <li>Finally check <code class="highlighter-rouge">(||d_theta_approx - d_theta||) / (||d_theta_approx||+||d_theta||)</code>
    <ul>
      <li>if it is &lt; 10^-7 - great, very likely the backpropagation implementation is correct</li>
      <li>if around 10^-5 - can be OK, but need to inspect if there are no particularly big values in <code class="highlighter-rouge">d_theta_approx - d_theta vector</code></li>
      <li>if it is &gt;= 10^-3 - bad, probably there is a bug in back propagation implementation</li>
    </ul>
  </li>
</ul>

<h5 id="gradient-checking-implementation-notes">Gradient checking implementation notes</h5>

<ul>
  <li>Don’t use the gradient checking algorithm at training time because it’s very slow.</li>
  <li>Use gradient checking only for debugging.</li>
  <li>If algorithm fails grad check, look at components to try to identify the bug.</li>
  <li>Don’t forget to add lamda/(2m) * sum(W[l]) to J if you are using L1 or L2 regularization.</li>
  <li>Gradient checking doesn’t work with dropout because J is not consistent.
    <ul>
      <li>You can first turn off dropout <code class="highlighter-rouge">(set keep_prob = 1.0)</code>, run gradient checking and then turn on dropout again.</li>
    </ul>
  </li>
  <li>Run gradient checking at random initialization and train the network for a while maybe there’s a bug which can be seen when w’s and b’s become larger (further from 0) and can’t be seen on the first iteration (when w’s and b’s are very small).</li>
</ul>

<h3 id="different-optimization-algorithms">Different Optimization algorithms</h3>
<p>Today, Deep learning is showing better performance because of availability of big data. But, training on huge data makes learning process much slower. So, In order to speed up  efficiency of learning models we use fast optimization algorithms like mini-batch gradient descent, stochastic gradient descent, Adagrad, momentum, RMSprop, and Adam.</p>

<h4 id="mini-batch-gradient-descent">Mini-batch gradient descent</h4>
<p>Suppose we have <code class="highlighter-rouge">m = 50 million</code>, to train this data it will take a huge processing time for one step. And also, 50 million won’t fit in the memory at once, so we need other processing to make such a thing.</p>

<p>In <code class="highlighter-rouge">Batch</code> gradient descent we run the gradient descent on the whole dataset. whereas, in <code class="highlighter-rouge">Mini-Batch</code> gradient descent we run the gradient descent on the mini datasets.</p>

<p>Some confusing terms:</p>
<blockquote>
  <p>Batch Size: Total number of training examples present in a single batch i.e. entire datasets</p>
</blockquote>

<blockquote>
  <p>Mini-batch: Small portion of training example taken from whole dataset. for example: 5 subset of 1 universal set.</p>
</blockquote>

<blockquote>
  <p>EPOCH : One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.</p>
</blockquote>

<blockquote>
  <p>Iterations is the number of batches needed to complete one epoch.</p>
</blockquote>

<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/mini-batch.png" alt="mini-batch" />
  </div>
</figure>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># Suppose we have split 5,000,000 training set to</span>
mini batches of size 1000.
    X<span class="o">{</span>1<span class="o">}</span> <span class="o">=</span> 0 ... 1000
    X<span class="o">{</span>2<span class="o">}</span> <span class="o">=</span> 1001 ... 2000
    ...
    X<span class="o">{}</span> <span class="o">=</span> ...
<span class="c"># here, X{1} is  1st mini-batch with 1000 training examples</span>
with its corresponding Y<span class="o">{</span>1<span class="o">}</span>      
</code></pre>
</div>
<h5 id="understanding-mini-batch-gradient-descent">Understanding mini-batch gradient descent</h5>
<ul>
  <li>
    <p>In mini-batch algorithm, the cost won’t go down with each step as it does in batch algorithm. It could contain some ups and downs but generally it has to go down (unlike the batch gradient descent where cost function descreases on each</p>
  </li>
  <li>
    <p><strong>Cost function in Batch vs Mini-batch gradient descent</strong>.</p>
  </li>
</ul>

<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/batch-minibatch.png" alt="mini-batch" />
  </div>
</figure>

<ul>
  <li>Mini-batch size:</li>
</ul>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="o">(</span>mini-batch size <span class="o">=</span> m<span class="o">)</span> <span class="o">==</span>&gt; Batch gradient descent
<span class="o">(</span>mini-batch size <span class="o">=</span> 1<span class="o">)</span> <span class="o">==</span>&gt; Stochastic gradient descent <span class="o">(</span>SGD<span class="o">)</span>
<span class="o">(</span>mini-batch size <span class="o">=</span> between 1 and m<span class="o">)</span> <span class="o">==</span>&gt; Mini-batch gradient descent
</code></pre>
</div>
<ul>
  <li>Batch gradient descent:
    <ul>
      <li>too long per iteration (epoch)</li>
    </ul>
  </li>
  <li>Stochastic gradient descent:
    <ul>
      <li>too noisy regarding cost minimization (can be reduced by using smaller learning rate)</li>
      <li>won’t ever converge (reach the minimum cost)
lose speedup from vectorization</li>
    </ul>
  </li>
  <li>Mini-batch gradient descent:
    <ul>
      <li>faster learning:
        <ul>
          <li>you have the vectorization advantage</li>
          <li>make progress without waiting to process the entire training set</li>
        </ul>
      </li>
      <li>doesn’t always exactly converge (oscelates in a very small region, but you can reduce learning rate)</li>
    </ul>
  </li>
  <li>Guidelines for choosing mini-batch size:
    <ul>
      <li>If small training set (&lt; 2000 examples) - use batch gradient descent.</li>
      <li>It has to be a power of 2 (because of the way computer memory is layed out and accessed, sometimes your code runs faster if your mini-batch size is a power of 2): 64, 128, 256, 512, 1024, …</li>
      <li>Make sure that mini-batch fits in CPU/GPU memory.</li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">Mini-batch</code> size is a <code class="highlighter-rouge">hyperparameter</code>.</li>
</ul>

<h4 id="exponentially-weighted-averages">Exponentially Weighted averages</h4>

<p>There are few optimization algorithm which are faster than gradient descent, they are all based on <code class="highlighter-rouge">exponentially Weighted averages</code> or exponentially weighted moving averages (in statistics).</p>

<ul>
  <li>If we have data like the temperature of day through the year it could be like this:</li>
</ul>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code>t<span class="o">(</span>1<span class="o">)</span> <span class="o">=</span> 40
t<span class="o">(</span>2<span class="o">)</span> <span class="o">=</span> 49
t<span class="o">(</span>3<span class="o">)</span> <span class="o">=</span> 45
...
t<span class="o">(</span>180<span class="o">)</span> <span class="o">=</span> 60
...

</code></pre>
</div>
<ul>
  <li>This data is small in winter and big in summer. If we plot this data we will find it some noisy.
Now lets compute the Exponentially weighted averages:</li>
</ul>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code>V0 <span class="o">=</span> 0
V1 <span class="o">=</span> 0.9 <span class="k">*</span> V0 + 0.1 <span class="k">*</span> t<span class="o">(</span>1<span class="o">)</span> <span class="o">=</span> 4		<span class="c"># 0.9 and 0.1 are hyperparameters</span>
V2 <span class="o">=</span> 0.9 <span class="k">*</span> V1 + 0.1 <span class="k">*</span> t<span class="o">(</span>2<span class="o">)</span> <span class="o">=</span> 8.5
V3 <span class="o">=</span> 0.9 <span class="k">*</span> V2 + 0.1 <span class="k">*</span> t<span class="o">(</span>3<span class="o">)</span> <span class="o">=</span> 12.15
...
</code></pre>
</div>

<ul>
  <li>General equation
    <div class="language-shell highlighter-rouge"><pre class="highlight"><code>V<span class="o">(</span>t<span class="o">)</span> <span class="o">=</span> beta <span class="k">*</span> v<span class="o">(</span>t-1<span class="o">)</span> + <span class="o">(</span>1-beta<span class="o">)</span> <span class="k">*</span> theta<span class="o">(</span>t<span class="o">)</span>
</code></pre>
    </div>
  </li>
  <li>If we plot this it will represent averages over ~ (1 / (1 - beta)) entries:
    <div class="language-shell highlighter-rouge"><pre class="highlight"><code>beta <span class="o">=</span> 0.9 will average last 10 entries
beta <span class="o">=</span> 0.98 will average last 50 entries
beta <span class="o">=</span> 0.5 will average last 2 entries
</code></pre>
    </div>
  </li>
</ul>
<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/weighted-average.png" alt="mini-batch" />
  </div>
</figure>

<ul>
  <li>Best beta average for our case is between 0.9 and 0.98</li>
</ul>

<h5 id="understanding-weighted-averages">Understanding Weighted averages</h5>
<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/weighted-intuition.png" alt="mini-batch" />
  </div>
</figure>

<p>We can implement this algorithm with more accurate results using a moving window. But the code is more efficient and faster using the exponentially weighted averages algorithm.
Algorithm is very simple:</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code>v <span class="o">=</span> 0
Repeat
<span class="o">{</span>
	Get theta<span class="o">(</span>t<span class="o">)</span>
	v <span class="o">=</span> beta <span class="k">*</span> v + <span class="o">(</span>1-beta<span class="o">)</span> <span class="k">*</span> theta<span class="o">(</span>t<span class="o">)</span>
<span class="o">}</span>

</code></pre>
</div>
<h5 id="bias-correction-in-exponentially-weighted-averages">Bias correction in exponentially weighted averages</h5>

<ul>
  <li>The bias correction helps make the exponentially weighted averages more accurate.</li>
  <li>Because v(0) = 0, the bias of the weighted averages is shifted and the accuracy suffers at the start.</li>
  <li>To solve the bias issue we have to use this equation:
<code class="highlighter-rouge">v(t) = (beta * v(t-1) + (1-beta) * theta(t)) / (1 - beta^t)</code></li>
  <li>As t becomes larger the <code class="highlighter-rouge">(1 - beta^t)</code> becomes close to 1</li>
</ul>

<h4 id="gradient-descent-with-momentum">Gradient Descent with momentum</h4>
<p>Gradient decent with momentum always work faster than gradient descent. <code class="highlighter-rouge">The basic idea is: to compute an exponentially weighted average of your gradients, and then use that gradient to update your weights instead</code>.</p>

<blockquote>
  <p>Our aim is to speed up learning in horizontal direction and slow down  learning in vertical direction.</p>
</blockquote>

<p>We want to move learning rate aggressively toward red dot with less oscillations. So implementing Gradient descent with momentum helps in this process.</p>

<figure>
 <div style="text-align:center">
   <img src="/assets/img/practical-aspect/lr-momentum.png" alt="mini-batch" />
 </div>
</figure>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># calculate the exponentially weighted averages for your gradients</span>
<span class="c"># and then update your weights with the new values.</span>
vdW <span class="o">=</span> 0, vdb <span class="o">=</span> 0
on iteration t:
	<span class="c"># can be mini-batch or batch gradient descent</span>
	compute dw, db on current mini-batch                

	vdW <span class="o">=</span> beta <span class="k">*</span> vdW + <span class="o">(</span>1 - beta<span class="o">)</span> <span class="k">*</span> dW
	vdb <span class="o">=</span> beta <span class="k">*</span> vdb + <span class="o">(</span>1 - beta<span class="o">)</span> <span class="k">*</span> db
	W <span class="o">=</span> W - learning_rate <span class="k">*</span> vdW
	b <span class="o">=</span> b - learning_rate <span class="k">*</span> vdb
</code></pre>
</div>
<ul>
  <li><code class="highlighter-rouge">beta</code> is another <code class="highlighter-rouge">hyperparameter</code>. <code class="highlighter-rouge">beta = 0.9</code> is very common and works very well in most cases</li>
  <li>In practice people don’t bother implementing <code class="highlighter-rouge">bias correction</code>.</li>
</ul>

<h4 id="rmsprop">RMSprop</h4>

<p>Root mean square prop. (RMSprop) is an algorithm speeds up the gradient descent. RMSprop will make the cost function move slower on the vertical direction and faster on the horizontal direction in the following example:</p>

<figure>
 <div style="text-align:center">
   <img src="/assets/img/practical-aspect/RMSprop.png" alt="mini-batch" />
 </div>
</figure>

<p><code class="highlighter-rouge">Note:</code> Ensure that sdW is not zero by adding a small value epsilon (e.g. epsilon = 10<sup>-8</sup>) to it:
<code class="highlighter-rouge">W = W - learning_rate * dW / (sqrt(sdW) + epsilon)</code>.</p>

<h4 id="adam-optimization-algorithm">Adam optimization algorithm</h4>
<p>RMSprop and Adam optimization algorithms are some algorithm which have shown to work well across a wide range of deep learning architectures. Adam optimization simply puts RMSprop and momentum together. Adam stands for <strong>Adaptive Moment Estimation</strong>.</p>

<p>Implementation of Adam</p>

<div class="language-c highlighter-rouge"><pre class="highlight"><code><span class="n">vdW</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vdW</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sdW</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sdb</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">on</span> <span class="n">iteration</span> <span class="n">t</span><span class="o">:</span>
	<span class="cp"># can be mini-batch or batch gradient descent
</span>	<span class="n">compute</span> <span class="n">dw</span><span class="p">,</span> <span class="n">db</span> <span class="n">on</span> <span class="n">current</span> <span class="n">mini</span><span class="o">-</span><span class="n">batch</span>                

	<span class="n">vdW</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta1</span> <span class="o">*</span> <span class="n">vdW</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dW</span>     <span class="err">#</span> <span class="n">momentum</span>
	<span class="n">vdb</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta1</span> <span class="o">*</span> <span class="n">vdb</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">db</span>     <span class="err">#</span> <span class="n">momentum</span>

	<span class="n">sdW</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta2</span> <span class="o">*</span> <span class="n">sdW</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">dW</span><span class="o">^</span><span class="mi">2</span>   <span class="err">#</span> <span class="n">RMSprop</span>
	<span class="n">sdb</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta2</span> <span class="o">*</span> <span class="n">sdb</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">db</span><span class="o">^</span><span class="mi">2</span>   <span class="err">#</span> <span class="n">RMSprop</span>

	<span class="n">vdW</span> <span class="o">=</span> <span class="n">vdW</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="o">^</span><span class="n">t</span><span class="p">)</span>      <span class="err">#</span> <span class="n">fixing</span> <span class="n">bias</span>
	<span class="n">vdb</span> <span class="o">=</span> <span class="n">vdb</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="o">^</span><span class="n">t</span><span class="p">)</span>      <span class="err">#</span> <span class="n">fixing</span> <span class="n">bias</span>

	<span class="n">sdW</span> <span class="o">=</span> <span class="n">sdW</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="o">^</span><span class="n">t</span><span class="p">)</span>      <span class="err">#</span> <span class="n">fixing</span> <span class="n">bias</span>
	<span class="n">sdb</span> <span class="o">=</span> <span class="n">sdb</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="o">^</span><span class="n">t</span><span class="p">)</span>      <span class="err">#</span> <span class="n">fixing</span> <span class="n">bias</span>

	<span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">vdW</span> <span class="o">/</span> <span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sdW</span><span class="p">)</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
	<span class="n">b</span> <span class="o">=</span> <span class="n">B</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">vdb</span> <span class="o">/</span> <span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sdb</span><span class="p">)</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
</code></pre>
</div>
<ul>
  <li>Hyperparameters for Adam:
    <ul>
      <li>Learning rate: needed to be tuned.</li>
      <li>beta1: parameter of the momentum - <code class="highlighter-rouge">0.9</code> is recommended by default.</li>
      <li>beta2: parameter of the RMSprop - <code class="highlighter-rouge">0.999</code> is recommended by default.</li>
      <li>epsilon: 10<sup>-8</sup> is recommended by default.</li>
    </ul>
  </li>
</ul>

<h4 id="learning-rate-decay">Learning rate decay</h4>
<p>we can speed up learning algorithm by slowly reducing the learning rate over time aka <code class="highlighter-rouge">learning rate decay</code>.</p>

<p>For mini-batch gradient decent, if learning rate (alpha) is fixed, then it won’t converge i.e. don’t reach the optimum point instead it will meander around  globlal minima. Like above figure. But by making the learning rate decay (decrease) with iterations it will be much closer to it because the steps (and possible oscillations) near the optimum are smaller.</p>

<p>As mentioned before mini-batch gradient descent won’t reach the optimum point (converge). But by making the learning rate decay with iterations it will be much closer to it because the steps (and possible oscillations) near the optimum are smaller.</p>

<p>One technique equations is <code class="highlighter-rouge">learning_rate = (1 / (1 + decay_rate * epoch_num)) * learning_rate_zero</code></p>

<figure>
  <div style="text-align:center">
    <img src="/assets/img/practical-aspect/lr-decay.png" alt="lr-decay" />
  </div>
</figure>

<blockquote>
  <p>We can divide the dataset of 2000 examples into batches of 500 then it will take 4 iterations to complete 1 epoch.</p>
</blockquote>

<ul>
  <li>Some people perform learning rate decay discretely - repeatedly decrease after some number of epochs.</li>
  <li>Some people are making changes to the learning rate manually.</li>
  <li>Other Learning rate decay methods
    <ul>
      <li>exponential decay:  <strong>learning_rate = 0.95<sup>epoch_num</sup> * learning_rate_zero</strong></li>
      <li><strong>learning_rate = k/sqrt(epoch_num) * learning_rate_zero</strong></li>
      <li>decrete staircase method</li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">decay_rate</code> is another <code class="highlighter-rouge">hyperparameter</code>.</li>
</ul>

<h4 id="the-problem-of-local-optima">The problem of local optima</h4>

<ul>
  <li>The normal local optima is not likely to appear in a deep neural network because data is usually high dimensional. For point to be a local optima it has to be a local optima for each of the dimensions which is highly unlikely.</li>
  <li>It’s unlikely to get stuck in a bad local optima in high dimensions, it is much more likely to get to the saddle point rather to the local optima, which is not a problem.</li>
  <li>Plateaus can make learning slow:
    <ul>
      <li>Plateau is a region where the derivative is close to zero for a long time.</li>
      <li>This is where algorithms like momentum, RMSprop or Adam can help.</li>
    </ul>
  </li>
</ul>

<h3 id="hyperparameter-tuning">Hyperparameter tuning</h3>

<h4 id="tuning-process">Tuning process</h4>
<h4 id="using-an-appropriate-scale-to-pick-hyperparameter">Using an appropriate scale to pick hyperparameter</h4>
<h4 id="hyperparameters-tuning-practice-pandas-vs-caviar">Hyperparameters tuning practice: Pandas vs. Caviar</h4>

<h3 id="batch-normalization">Batch Normalization</h3>

<h4 id="normalizing-activations-in-a-network">Normalizing activations in a network</h4>
<h4 id="fitting-batch-norm-into-neural-network">Fitting Batch Norm into neural network</h4>
<h4 id="why-does-batch-norm-work">Why does Batch Norm Work</h4>
<h4 id="batch-norm-at-test-time">Batch Norm at test time</h4>

<h3 id="multiclass-classification">Multiclass classification</h3>

<h4 id="softmax-regression">Softmax Regression</h4>
<h4 id="training-a-softmax-classifier">Training a Softmax classifier</h4>

<h3 id="introduction-to-programming-frameworks">Introduction to programming Frameworks</h3>

    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="/assets/img/profile.png" alt="">
      </div>
      <div class="author-name" rel="author">bikash</div>
      <div class="bio">
        <p></p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="https://www.linkedin.com/in/bikashjaiswal" target="_blank">
                    <i class="iconfont icon-linkedin"></i>
                </a>
        </li>
        
        <li>
          <a href="https://www.github.com/bikash-jaiswal" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
        <li>
          <a href="bjjaiswal@gmail.com" target="_blank">
                    <i class="iconfont icon-email"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2018/04/20/Machine-Learning-Strategy-in-Deep-Learning.html" class="read-next-link"></a>
        <section>
          <span>How to Structure Machine Learning Projects</span>
          <p>Even after developing a model, We find that prediction ac...</p>
        </section>
        
        <div class="filter"></div>
        <img src="https://i2.wp.com/philosophyofbrains.com/wp-content/uploads/2016/05/Problem-Mental-Causation-Pic.jpg?resize=1280%2C585" alt="">
        
     </div>
      

      
    </section>
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
    </section>
  </section>

  <footer class="g-footer">
  <section>Bikash-Jaiswal Blog ©
  
  
    2017
    -
  
  2018
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a> | <a href="https://github.com/kaeyleo/jekyll-theme-H2O">Theme H2O</a></section>
</footer>



  
  <script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document,
        s = d.createElement('script');
      s.src = 'https://bikash-jaiswal.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());

      (d.head || d.body).appendChild(s);
    })();
  </script>
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
